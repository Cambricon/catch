,has_error,info,op_name
0,yes,"<class 'RuntimeError'> : ""lshift_cpu"" not implemented for 'Half'
",test___lshift___mlu_float16
1,yes,"<class 'RuntimeError'> : Could not run 'aten::__lshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__lshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___lshift___mlu_float32
2,yes,"<class 'RuntimeError'> : Could not run 'aten::__lshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__lshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___lshift___mlu_float64
3,yes,"<class 'RuntimeError'> : Could not run 'aten::__lshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__lshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___lshift___mlu_int16
4,yes,"<class 'RuntimeError'> : Could not run 'aten::__lshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__lshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___lshift___mlu_int32
5,yes,"<class 'RuntimeError'> : Could not run 'aten::__lshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__lshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___lshift___mlu_int64
6,yes,"<class 'RuntimeError'> : Could not run 'aten::__lshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__lshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___lshift___mlu_int8
7,yes,"<class 'RuntimeError'> : ""rshift_cpu"" not implemented for 'Half'
",test___rshift___mlu_float16
8,yes,"<class 'RuntimeError'> : Could not run 'aten::__rshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__rshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___rshift___mlu_float32
9,yes,"<class 'RuntimeError'> : Could not run 'aten::__rshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__rshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___rshift___mlu_float64
10,yes,"<class 'RuntimeError'> : Could not run 'aten::__rshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__rshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___rshift___mlu_int16
11,yes,"<class 'RuntimeError'> : Could not run 'aten::__rshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__rshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___rshift___mlu_int32
12,yes,"<class 'RuntimeError'> : Could not run 'aten::__rshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__rshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___rshift___mlu_int64
13,yes,"<class 'RuntimeError'> : Could not run 'aten::__rshift__.Scalar' with arguments from the 'MLU' backend. 'aten::__rshift__.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test___rshift___mlu_int8
14,no,,test_abs_inplace_mlu_float16
15,no,,test_abs_inplace_mlu_float32
16,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 64 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 4.701587666036689 (2.3507938275357128 vs. -2.3507938385009766), which occurred at index (2, 2, 4).
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 568][abs_][thread:140219569719040][process:16986]: OpMethods::abs_ Op running on CPU!
",test_abs_inplace_mlu_float64
17,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 63 different element(s) (out of 125), with the greatest difference of 10 (5 vs. -5) occuring at index (4, 2, 4).
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUShortType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 568][abs_][thread:140219569719040][process:16986]: OpMethods::abs_ Op running on CPU!
",test_abs_inplace_mlu_int16
18,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 67 different element(s) (out of 125), with the greatest difference of 10 (5 vs. -5) occuring at index (4, 3, 4).
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUIntType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 568][abs_][thread:140219569719040][process:16986]: OpMethods::abs_ Op running on CPU!
",test_abs_inplace_mlu_int32
19,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 68 different element(s) (out of 125), with the greatest difference of 10 (5 vs. -5) occuring at index (4, 4, 1).
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLULongType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 568][abs_][thread:140219569719040][process:16986]: OpMethods::abs_ Op running on CPU!
",test_abs_inplace_mlu_int64
20,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 68 different element(s) (out of 125), with the greatest difference of 10 (5 vs. -5) occuring at index (4, 3, 4).
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUCharType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 568][abs_][thread:140219569719040][process:16986]: OpMethods::abs_ Op running on CPU!
",test_abs_inplace_mlu_int8
21,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUByteType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 568][abs_][thread:140219569719040][process:16986]: OpMethods::abs_ Op running on CPU!
",test_abs_inplace_mlu_uint8
22,no,,test_abs_mlu_float16
23,no,,test_abs_mlu_float32
24,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_abs_mlu_float64
25,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUShortType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_abs_mlu_int16
26,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUIntType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_abs_mlu_int32
27,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLULongType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_abs_mlu_int64
28,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUCharType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_abs_mlu_int8
29,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUByteType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_abs_mlu_uint8
30,yes,"<class 'RuntimeError'> : acos_vml_cpu not implemented for 'Half'
",test_acos_inplace_mlu_float16
31,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_acos_inplace_mlu_float32
32,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got -nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_acos_inplace_mlu_float64
33,yes,"<class 'RuntimeError'> : acos_vml_cpu not implemented for 'Half'
",test_acos_mlu_float16
34,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_acos_mlu_float32
35,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got -nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_acos_mlu_float64
36,yes,"<class 'RuntimeError'> : ""acosh_cpu"" not implemented for 'Half'
",test_acosh_inplace_mlu_float16
37,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_acosh_inplace_mlu_float32
38,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got -nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_acosh_inplace_mlu_float64
39,yes,"<class 'RuntimeError'> : ""acosh_cpu"" not implemented for 'Half'
",test_acosh_mlu_float16
40,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_acosh_mlu_float32
41,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got -nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_acosh_mlu_float64
42,no,,test_add_inplace_mlu_float16
43,no,,test_add_inplace_mlu_float32
44,no,,test_add_inplace_mlu_float64
45,no,,test_add_inplace_mlu_int16
46,no,,test_add_inplace_mlu_int32
47,no,,test_add_inplace_mlu_int64
48,no,,test_add_inplace_mlu_int8
49,no,,test_add_inplace_mlu_uint8
50,no,,test_add_inplace_tensor_mlu_float16
51,no,,test_add_inplace_tensor_mlu_float32
52,no,,test_add_inplace_tensor_mlu_float64
53,no,,test_add_inplace_tensor_mlu_int16
54,no,,test_add_inplace_tensor_mlu_int32
55,no,,test_add_inplace_tensor_mlu_int64
56,no,,test_add_inplace_tensor_mlu_int8
57,no,,test_add_inplace_tensor_mlu_uint8
58,no,,test_add_mlu_float16
59,no,,test_add_mlu_float32
60,no,,test_add_mlu_float64
61,no,,test_add_mlu_int16
62,no,,test_add_mlu_int32
63,no,,test_add_mlu_int64
64,no,,test_add_mlu_int8
65,no,,test_add_mlu_uint8
66,no,,test_add_tensor_mlu_float16
67,no,,test_add_tensor_mlu_float32
68,no,,test_add_tensor_mlu_float64
69,no,,test_add_tensor_mlu_int16
70,no,,test_add_tensor_mlu_int32
71,no,,test_add_tensor_mlu_int64
72,no,,test_add_tensor_mlu_int8
73,no,,test_add_tensor_mlu_uint8
74,yes,"<class 'RuntimeError'> : _th_addbmm_ not supported on CPUType for Half
",test_addbmm_inplace_mlu_float16
75,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm_' with arguments from the 'MLU' backend. 'aten::addbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addbmm_inplace_mlu_float32
76,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm_' with arguments from the 'MLU' backend. 'aten::addbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addbmm_inplace_mlu_float64
77,yes,"<class 'RuntimeError'> : _th_addbmm_ not supported on CPUType for Half
",test_addbmm_inplace_scalar_mlu_float16
78,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm_' with arguments from the 'MLU' backend. 'aten::addbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addbmm_inplace_scalar_mlu_float32
79,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm_' with arguments from the 'MLU' backend. 'aten::addbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addbmm_inplace_scalar_mlu_float64
80,yes,"<class 'RuntimeError'> : _th_addbmm_ not supported on CPUType for Half
",test_addbmm_inplace_two_scalars_mlu_float16
81,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm_' with arguments from the 'MLU' backend. 'aten::addbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addbmm_inplace_two_scalars_mlu_float32
82,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm_' with arguments from the 'MLU' backend. 'aten::addbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addbmm_inplace_two_scalars_mlu_float64
83,yes,"<class 'RuntimeError'> : _th_addbmm not supported on CPUType for Half
",test_addbmm_mlu_float16
84,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm' with arguments from the 'MLU' backend. 'aten::addbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_addbmm_mlu_float32
85,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm' with arguments from the 'MLU' backend. 'aten::addbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_addbmm_mlu_float64
86,yes,"<class 'RuntimeError'> : _th_addbmm not supported on CPUType for Half
",test_addbmm_scalar_mlu_float16
87,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm' with arguments from the 'MLU' backend. 'aten::addbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_addbmm_scalar_mlu_float32
88,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm' with arguments from the 'MLU' backend. 'aten::addbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_addbmm_scalar_mlu_float64
89,yes,"<class 'RuntimeError'> : _th_addbmm not supported on CPUType for Half
",test_addbmm_two_scalars_mlu_float16
90,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm' with arguments from the 'MLU' backend. 'aten::addbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_addbmm_two_scalars_mlu_float32
91,yes,"<class 'RuntimeError'> : Could not run 'aten::addbmm' with arguments from the 'MLU' backend. 'aten::addbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_addbmm_two_scalars_mlu_float64
92,no,,test_addcdiv_inplace_mlu_float16
93,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 9 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.015228271484375 (-407.5611877441406 vs. -407.54595947265625), which occurred at index (4, 3).
",test_addcdiv_inplace_mlu_float32
94,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 12 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.022648351536531663 (-607.2375531366928 vs. -607.2149047851562), which occurred at index (1, 3).
",test_addcdiv_inplace_mlu_float64
95,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1, found 1 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.0101318359375 (1458.9898681640625 vs. 1460.0), which occurred at index (2, 2).
",test_addcdiv_inplace_scalar_mlu_float16
96,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 14 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0584716796875 (1564.830810546875 vs. 1564.7723388671875), which occurred at index (4, 0).
",test_addcdiv_inplace_scalar_mlu_float32
97,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 12 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.03400758253519598 (-909.795177016129 vs. -909.7611694335938), which occurred at index (4, 3).
",test_addcdiv_inplace_scalar_mlu_float64
98,no,,test_addcdiv_mlu_float16
99,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 13 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.013763427734375 (-369.3521423339844 vs. -369.33837890625), which occurred at index (1, 4).
",test_addcdiv_mlu_float32
100,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 18 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.021086747316189758 (-563.6373587199724 vs. -563.6162719726562), which occurred at index (4, 4).
",test_addcdiv_mlu_float64
101,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1, found 1 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.033447265625 (-1522.966552734375 vs. -1524.0), which occurred at index (0, 3).
",test_addcdiv_scalar_mlu_float16
102,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 8 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.058349609375 (-1561.5135498046875 vs. -1561.4552001953125), which occurred at index (3, 4).
",test_addcdiv_scalar_mlu_float32
103,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 12 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.06074799534508202 (1620.79048432347 vs. 1620.729736328125), which occurred at index (2, 3).
",test_addcdiv_scalar_mlu_float64
104,no,,test_addcmul_inplace_mlu_float16
105,no,,test_addcmul_inplace_mlu_float32
106,no,,test_addcmul_inplace_mlu_float64
107,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 119 different element(s) (out of 125), with the greatest difference of 31765 (-20 vs. 31745) occuring at index (0, 4, 2).
",test_addcmul_inplace_mlu_int16
108,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 110 different element(s) (out of 125), with the greatest difference of 2080472087 (-22 vs. 2080472065) occuring at index (0, 4, 4).
",test_addcmul_inplace_mlu_int32
109,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 110 different element(s) (out of 125), with the greatest difference of 2080472085 (-20 vs. 2080472065) occuring at index (1, 3, 4).
",test_addcmul_inplace_mlu_int64
110,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 121 different element(s) (out of 125), with the greatest difference of 141 (-17 vs. 124) occuring at index (0, 1, 0).
",test_addcmul_inplace_mlu_int8
111,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 93 different element(s) (out of 125), with the greatest difference of 72 (75 vs. 3) occuring at index (2, 1, 0).
",test_addcmul_inplace_mlu_uint8
112,no,,test_addcmul_inplace_scalar_mlu_float16
113,no,,test_addcmul_inplace_scalar_mlu_float32
114,no,,test_addcmul_inplace_scalar_mlu_float64
115,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 123 different element(s) (out of 125), with the greatest difference of 31787 (-42 vs. 31745) occuring at index (1, 4, 1).
",test_addcmul_inplace_scalar_mlu_int16
116,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 113 different element(s) (out of 125), with the greatest difference of 2080472103 (-38 vs. 2080472065) occuring at index (1, 3, 0).
",test_addcmul_inplace_scalar_mlu_int32
117,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 109 different element(s) (out of 125), with the greatest difference of 2080472102 (-37 vs. 2080472065) occuring at index (1, 1, 3).
",test_addcmul_inplace_scalar_mlu_int64
118,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 122 different element(s) (out of 125), with the greatest difference of 154 (-30 vs. 124) occuring at index (3, 0, 0).
",test_addcmul_inplace_scalar_mlu_int8
119,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 101 different element(s) (out of 125), with the greatest difference of 162 (165 vs. 3) occuring at index (0, 4, 2).
",test_addcmul_inplace_scalar_mlu_uint8
120,no,,test_addcmul_mlu_float16
121,no,,test_addcmul_mlu_float32
122,no,,test_addcmul_mlu_float64
123,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 119 different element(s) (out of 125), with the greatest difference of 31768 (-23 vs. 31745) occuring at index (2, 2, 4).
",test_addcmul_mlu_int16
124,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 118 different element(s) (out of 125), with the greatest difference of 2080472085 (-20 vs. 2080472065) occuring at index (2, 3, 1).
",test_addcmul_mlu_int32
125,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 123 different element(s) (out of 125), with the greatest difference of 2080472087 (-22 vs. 2080472065) occuring at index (1, 3, 4).
",test_addcmul_mlu_int64
126,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 116 different element(s) (out of 125), with the greatest difference of 140 (-16 vs. 124) occuring at index (2, 0, 3).
",test_addcmul_mlu_int8
127,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 97 different element(s) (out of 125), with the greatest difference of 81 (86 vs. 5) occuring at index (0, 0, 4).
",test_addcmul_mlu_uint8
128,no,,test_addcmul_scalar_mlu_float16
129,no,,test_addcmul_scalar_mlu_float32
130,no,,test_addcmul_scalar_mlu_float64
131,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 122 different element(s) (out of 125), with the greatest difference of 31790 (-45 vs. 31745) occuring at index (3, 1, 4).
",test_addcmul_scalar_mlu_int16
132,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 124 different element(s) (out of 125), with the greatest difference of 2080472101 (-36 vs. 2080472065) occuring at index (1, 0, 0).
",test_addcmul_scalar_mlu_int32
133,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 121 different element(s) (out of 125), with the greatest difference of 2080472105 (-40 vs. 2080472065) occuring at index (1, 0, 4).
",test_addcmul_scalar_mlu_int64
134,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 120 different element(s) (out of 125), with the greatest difference of 155 (-31 vs. 124) occuring at index (4, 4, 3).
",test_addcmul_scalar_mlu_int8
135,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 95 different element(s) (out of 125), with the greatest difference of 162 (164 vs. 2) occuring at index (0, 4, 0).
",test_addcmul_scalar_mlu_uint8
136,yes,"<class 'RuntimeError'> : _th_addmm_ not supported on CPUType for Half
",test_addmm_inplace_mlu_float16
137,yes,"<class 'RuntimeError'> : Could not run 'aten::addmm_' with arguments from the 'MLU' backend. 'aten::addmm_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_addmm_inplace_mlu_float32
138,yes,"<class 'RuntimeError'> : Could not run 'aten::addmm_' with arguments from the 'MLU' backend. 'aten::addmm_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_addmm_inplace_mlu_float64
139,yes,"<class 'RuntimeError'> : _th_addmm_ not supported on CPUType for Half
",test_addmm_inplace_scalar_mlu_float16
140,yes,"<class 'RuntimeError'> : Could not run 'aten::addmm_' with arguments from the 'MLU' backend. 'aten::addmm_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_addmm_inplace_scalar_mlu_float32
141,yes,"<class 'RuntimeError'> : Could not run 'aten::addmm_' with arguments from the 'MLU' backend. 'aten::addmm_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_addmm_inplace_scalar_mlu_float64
142,yes,"<class 'RuntimeError'> : _th_addmm_ not supported on CPUType for Half
",test_addmm_inplace_two_scalars_mlu_float16
143,yes,"<class 'RuntimeError'> : Could not run 'aten::addmm_' with arguments from the 'MLU' backend. 'aten::addmm_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_addmm_inplace_two_scalars_mlu_float32
144,yes,"<class 'RuntimeError'> : Could not run 'aten::addmm_' with arguments from the 'MLU' backend. 'aten::addmm_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_addmm_inplace_two_scalars_mlu_float64
145,yes,"[2021-7-16 18:29:49] [CNNL] [Error]: [cnnlQuantizeMatMul] Check failed: compute_dtype == CNNL_DTYPE_FLOAT. 
[2021-7-16 18:29:49] [CNNL] [Error]: [cnnlQuantizeMatMul]:cnnlGetQuantizeMatMulAlgorithm() Check failed: CNNL_STATUS_SUCCESS == checkShapeDType(trans_a, trans_b, a_desc, b_desc, c_desc, compute_dtype). 
<class 'RuntimeError'> : _th_addmm not supported on CPUType for Half
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/cnnl/cnnlAlgorithms.cpp][line: 19][get][thread:139707717867264][process:64381]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 182][addmm][thread:139707717867264][process:64381]: OpMethods::addmm Op running on CPU!
",test_addmm_mlu_float16
146,no,,test_addmm_mlu_float32
147,no,,test_addmm_mlu_float64
148,yes,"[2021-7-16 18:29:49] [CNNL] [Error]: [cnnlQuantizeMatMul] Check failed: compute_dtype == CNNL_DTYPE_FLOAT. 
[2021-7-16 18:29:49] [CNNL] [Error]: [cnnlQuantizeMatMul]:cnnlGetQuantizeMatMulAlgorithm() Check failed: CNNL_STATUS_SUCCESS == checkShapeDType(trans_a, trans_b, a_desc, b_desc, c_desc, compute_dtype). 
<class 'RuntimeError'> : _th_addmm not supported on CPUType for Half
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/cnnl/cnnlAlgorithms.cpp][line: 19][get][thread:139707717867264][process:64381]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 182][addmm][thread:139707717867264][process:64381]: OpMethods::addmm Op running on CPU!
",test_addmm_scalar_mlu_float16
149,no,,test_addmm_scalar_mlu_float32
150,no,,test_addmm_scalar_mlu_float64
151,yes,"[2021-7-16 18:29:49] [CNNL] [Error]: [cnnlQuantizeMatMul] Check failed: compute_dtype == CNNL_DTYPE_FLOAT. 
[2021-7-16 18:29:49] [CNNL] [Error]: [cnnlQuantizeMatMul]:cnnlGetQuantizeMatMulAlgorithm() Check failed: CNNL_STATUS_SUCCESS == checkShapeDType(trans_a, trans_b, a_desc, b_desc, c_desc, compute_dtype). 
<class 'RuntimeError'> : _th_addmm not supported on CPUType for Half
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/cnnl/cnnlAlgorithms.cpp][line: 19][get][thread:139707717867264][process:64381]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 182][addmm][thread:139707717867264][process:64381]: OpMethods::addmm Op running on CPU!
",test_addmm_two_scalars_mlu_float16
152,no,,test_addmm_two_scalars_mlu_float32
153,no,,test_addmm_two_scalars_mlu_float64
154,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_inplace_mlu_complex128
155,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_inplace_mlu_complex64
156,yes,"<class 'RuntimeError'> : ""addmv_impl_cpu"" not implemented for 'Half'
",test_addmv_inplace_mlu_float16
157,yes,"<class 'RuntimeError'> : Could not run 'aten::_addmv_impl_' with arguments from the 'MLU' backend. 'aten::_addmv_impl_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addmv_inplace_mlu_float32
158,yes,"<class 'RuntimeError'> : Could not run 'aten::_addmv_impl_' with arguments from the 'MLU' backend. 'aten::_addmv_impl_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addmv_inplace_mlu_float64
159,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_inplace_scalar_mlu_complex128
160,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_inplace_scalar_mlu_complex64
161,yes,"<class 'RuntimeError'> : ""addmv_impl_cpu"" not implemented for 'Half'
",test_addmv_inplace_scalar_mlu_float16
162,yes,"<class 'RuntimeError'> : Could not run 'aten::_addmv_impl_' with arguments from the 'MLU' backend. 'aten::_addmv_impl_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addmv_inplace_scalar_mlu_float32
163,yes,"<class 'RuntimeError'> : Could not run 'aten::_addmv_impl_' with arguments from the 'MLU' backend. 'aten::_addmv_impl_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addmv_inplace_scalar_mlu_float64
164,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_inplace_two_scalars_mlu_complex128
165,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_inplace_two_scalars_mlu_complex64
166,yes,"<class 'RuntimeError'> : ""addmv_impl_cpu"" not implemented for 'Half'
",test_addmv_inplace_two_scalars_mlu_float16
167,yes,"<class 'RuntimeError'> : Could not run 'aten::_addmv_impl_' with arguments from the 'MLU' backend. 'aten::_addmv_impl_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addmv_inplace_two_scalars_mlu_float32
168,yes,"<class 'RuntimeError'> : Could not run 'aten::_addmv_impl_' with arguments from the 'MLU' backend. 'aten::_addmv_impl_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addmv_inplace_two_scalars_mlu_float64
169,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_mlu_complex128
170,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_mlu_complex64
171,yes,"<class 'RuntimeError'> : ""addmv_impl_cpu"" not implemented for 'Half'
",test_addmv_mlu_float16
172,yes,"<class 'RuntimeError'> : is_supported_device(self.device()) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/Copy.cpp"":112, please report a bug to PyTorch. 
",test_addmv_mlu_float32
173,yes,"<class 'RuntimeError'> : is_supported_device(self.device()) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/Copy.cpp"":112, please report a bug to PyTorch. 
",test_addmv_mlu_float64
174,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_scalar_mlu_complex128
175,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_scalar_mlu_complex64
176,yes,"<class 'RuntimeError'> : ""addmv_impl_cpu"" not implemented for 'Half'
",test_addmv_scalar_mlu_float16
177,yes,"<class 'RuntimeError'> : is_supported_device(self.device()) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/Copy.cpp"":112, please report a bug to PyTorch. 
",test_addmv_scalar_mlu_float32
178,yes,"<class 'RuntimeError'> : is_supported_device(self.device()) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/Copy.cpp"":112, please report a bug to PyTorch. 
",test_addmv_scalar_mlu_float64
179,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_two_scalars_mlu_complex128
180,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_addmv_two_scalars_mlu_complex64
181,yes,"<class 'RuntimeError'> : ""addmv_impl_cpu"" not implemented for 'Half'
",test_addmv_two_scalars_mlu_float16
182,yes,"<class 'RuntimeError'> : is_supported_device(self.device()) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/Copy.cpp"":112, please report a bug to PyTorch. 
",test_addmv_two_scalars_mlu_float32
183,yes,"<class 'RuntimeError'> : is_supported_device(self.device()) INTERNAL ASSERT FAILED at ""../aten/src/ATen/native/Copy.cpp"":112, please report a bug to PyTorch. 
",test_addmv_two_scalars_mlu_float64
184,yes,"<class 'RuntimeError'> : _th_addr_ not supported on CPUType for Half
",test_addr_inplace_mlu_float16
185,yes,"<class 'RuntimeError'> : Could not run 'aten::_addr_' with arguments from the 'MLU' backend. 'aten::_addr_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addr_inplace_mlu_float32
186,yes,"<class 'RuntimeError'> : Could not run 'aten::_addr_' with arguments from the 'MLU' backend. 'aten::_addr_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addr_inplace_mlu_float64
187,yes,"<class 'RuntimeError'> : _th_addr_ not supported on CPUType for Half
",test_addr_inplace_scalar_mlu_float16
188,yes,"<class 'RuntimeError'> : Could not run 'aten::_addr_' with arguments from the 'MLU' backend. 'aten::_addr_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addr_inplace_scalar_mlu_float32
189,yes,"<class 'RuntimeError'> : Could not run 'aten::_addr_' with arguments from the 'MLU' backend. 'aten::_addr_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addr_inplace_scalar_mlu_float64
190,yes,"<class 'RuntimeError'> : _th_addr_ not supported on CPUType for Half
",test_addr_inplace_two_scalars_mlu_float16
191,yes,"<class 'RuntimeError'> : Could not run 'aten::_addr_' with arguments from the 'MLU' backend. 'aten::_addr_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addr_inplace_two_scalars_mlu_float32
192,yes,"<class 'RuntimeError'> : Could not run 'aten::_addr_' with arguments from the 'MLU' backend. 'aten::_addr_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_addr_inplace_two_scalars_mlu_float64
193,no,,test_addr_mlu_float16
194,no,,test_addr_mlu_float32
195,no,,test_addr_mlu_float64
196,no,,test_addr_scalar_mlu_float16
197,no,,test_addr_scalar_mlu_float32
198,no,,test_addr_scalar_mlu_float64
199,no,,test_addr_two_scalars_mlu_float16
200,no,,test_addr_two_scalars_mlu_float32
201,no,,test_addr_two_scalars_mlu_float64
202,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_angle_mlu_float32
203,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0, found 125 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 9.614479790087671e-08 (2.334505461869118 vs. 2.334505558013916), which occurred at index (2, 4, 0).
",test_angle_mlu_float64
204,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_angle_mlu_int16
205,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_angle_mlu_int32
206,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_angle_mlu_int64
207,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_angle_mlu_int8
208,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_angle_mlu_uint8
209,yes,"<class 'RuntimeError'> : asin_vml_cpu not implemented for 'Half'
",test_asin_inplace_mlu_float16
210,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_asin_inplace_mlu_float32
211,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_asin_inplace_mlu_float64
212,yes,"<class 'RuntimeError'> : asin_vml_cpu not implemented for 'Half'
",test_asin_mlu_float16
213,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_asin_mlu_float32
214,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_asin_mlu_float64
215,yes,"<class 'RuntimeError'> : ""asinh_cpu"" not implemented for 'Half'
",test_asinh_inplace_mlu_float16
216,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_asinh_inplace_mlu_float32
217,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_asinh_inplace_mlu_float64
218,yes,"<class 'RuntimeError'> : ""asinh_cpu"" not implemented for 'Half'
",test_asinh_mlu_float16
219,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_asinh_mlu_float32
220,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_asinh_mlu_float64
221,yes,"<class 'RuntimeError'> : ""atan2_cpu"" not implemented for 'Half'
",test_atan2_inplace_mlu_float16
222,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan2_inplace_mlu_float32
223,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan2_inplace_mlu_float64
224,yes,"<class 'RuntimeError'> : ""atan2_cpu"" not implemented for 'Half'
",test_atan2_mlu_float16
225,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan2_mlu_float32
226,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan2_mlu_float64
227,yes,"<class 'RuntimeError'> : atan_vml_cpu not implemented for 'Half'
",test_atan_inplace_mlu_float16
228,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan_inplace_mlu_float32
229,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan_inplace_mlu_float64
230,yes,"<class 'RuntimeError'> : atan_vml_cpu not implemented for 'Half'
",test_atan_mlu_float16
231,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan_mlu_float32
232,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atan_mlu_float64
233,yes,"<class 'RuntimeError'> : ""atanh_cpu"" not implemented for 'Half'
",test_atanh_inplace_mlu_float16
234,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atanh_inplace_mlu_float32
235,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got -nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_atanh_inplace_mlu_float64
236,yes,"<class 'RuntimeError'> : ""atanh_cpu"" not implemented for 'Half'
",test_atanh_mlu_float16
237,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_atanh_mlu_float32
238,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got -nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_atanh_mlu_float64
239,yes,"<class 'RuntimeError'> : ""baddbmm"" not implemented for 'Half'
",test_baddbmm_inplace_mlu_float16
240,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm_' with arguments from the 'MLU' backend. 'aten::baddbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_baddbmm_inplace_mlu_float32
241,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm_' with arguments from the 'MLU' backend. 'aten::baddbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_baddbmm_inplace_mlu_float64
242,yes,"<class 'RuntimeError'> : ""baddbmm"" not implemented for 'Half'
",test_baddbmm_inplace_scalar_mlu_float16
243,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm_' with arguments from the 'MLU' backend. 'aten::baddbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_baddbmm_inplace_scalar_mlu_float32
244,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm_' with arguments from the 'MLU' backend. 'aten::baddbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_baddbmm_inplace_scalar_mlu_float64
245,yes,"<class 'RuntimeError'> : ""baddbmm"" not implemented for 'Half'
",test_baddbmm_inplace_two_scalars_mlu_float16
246,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm_' with arguments from the 'MLU' backend. 'aten::baddbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_baddbmm_inplace_two_scalars_mlu_float32
247,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm_' with arguments from the 'MLU' backend. 'aten::baddbmm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_baddbmm_inplace_two_scalars_mlu_float64
248,yes,"<class 'RuntimeError'> : ""baddbmm"" not implemented for 'Half'
",test_baddbmm_mlu_float16
249,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm' with arguments from the 'MLU' backend. 'aten::baddbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_baddbmm_mlu_float32
250,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm' with arguments from the 'MLU' backend. 'aten::baddbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_baddbmm_mlu_float64
251,yes,"<class 'RuntimeError'> : ""baddbmm"" not implemented for 'Half'
",test_baddbmm_scalar_mlu_float16
252,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm' with arguments from the 'MLU' backend. 'aten::baddbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_baddbmm_scalar_mlu_float32
253,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm' with arguments from the 'MLU' backend. 'aten::baddbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_baddbmm_scalar_mlu_float64
254,yes,"<class 'RuntimeError'> : ""baddbmm"" not implemented for 'Half'
",test_baddbmm_two_scalars_mlu_float16
255,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm' with arguments from the 'MLU' backend. 'aten::baddbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_baddbmm_two_scalars_mlu_float32
256,yes,"<class 'RuntimeError'> : Could not run 'aten::baddbmm' with arguments from the 'MLU' backend. 'aten::baddbmm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_baddbmm_two_scalars_mlu_float64
257,no,,test_bmm_mlu_float32
258,no,,test_bmm_mlu_float64
259,yes,"<class 'RuntimeError'> : ceil_vml_cpu not implemented for 'Half'
",test_ceil_inplace_mlu_float16
260,yes,"<class 'RuntimeError'> : Could not run 'aten::ceil.out' with arguments from the 'MLU' backend. 'aten::ceil.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_ceil_inplace_mlu_float32
261,yes,"<class 'RuntimeError'> : Could not run 'aten::ceil.out' with arguments from the 'MLU' backend. 'aten::ceil.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_ceil_inplace_mlu_float64
262,yes,"<class 'RuntimeError'> : ceil_vml_cpu not implemented for 'Half'
",test_ceil_mlu_float16
263,yes,"<class 'RuntimeError'> : Could not run 'aten::ceil.out' with arguments from the 'MLU' backend. 'aten::ceil.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_ceil_mlu_float32
264,yes,"<class 'RuntimeError'> : Could not run 'aten::ceil.out' with arguments from the 'MLU' backend. 'aten::ceil.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_ceil_mlu_float64
265,no,,test_chunk_dim_mlu_float16
266,no,,test_chunk_dim_mlu_float32
267,no,,test_chunk_dim_mlu_float64
268,no,,test_chunk_dim_mlu_int16
269,no,,test_chunk_dim_mlu_int32
270,no,,test_chunk_dim_mlu_int64
271,no,,test_chunk_dim_mlu_int8
272,no,,test_chunk_dim_mlu_uint8
273,no,,test_chunk_mlu_float16
274,no,,test_chunk_mlu_float32
275,no,,test_chunk_mlu_float64
276,no,,test_chunk_mlu_int16
277,no,,test_chunk_mlu_int32
278,no,,test_chunk_mlu_int64
279,no,,test_chunk_mlu_int8
280,no,,test_chunk_mlu_uint8
281,no,,test_chunk_neg_dim_mlu_float16
282,no,,test_chunk_neg_dim_mlu_float32
283,no,,test_chunk_neg_dim_mlu_float64
284,no,,test_chunk_neg_dim_mlu_int16
285,no,,test_chunk_neg_dim_mlu_int32
286,no,,test_chunk_neg_dim_mlu_int64
287,no,,test_chunk_neg_dim_mlu_int8
288,no,,test_chunk_neg_dim_mlu_uint8
289,no,,test_clamp_inplace_neg_mlu_float16
290,no,,test_clamp_inplace_neg_mlu_float32
291,no,,test_clamp_inplace_neg_mlu_float64
292,no,,test_clamp_inplace_neg_mlu_int16
293,no,,test_clamp_inplace_neg_mlu_int32
294,no,,test_clamp_inplace_neg_mlu_int64
295,no,,test_clamp_inplace_neg_mlu_int8
296,no,,test_clamp_inplace_pos_mlu_uint8
297,yes,"<class 'RuntimeError'> : ""clamp_max_cpu"" not implemented for 'Half'
",test_clamp_max_inplace_mlu_float16
298,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_float32
299,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_float64
300,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_int16
301,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_int32
302,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_int64
303,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_int8
304,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_inplace_mlu_uint8
305,yes,"<class 'RuntimeError'> : ""clamp_max_cpu"" not implemented for 'Half'
",test_clamp_max_mlu_float16
306,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_float32
307,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_float64
308,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_int16
309,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_int32
310,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_int64
311,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_int8
312,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_clamp_max_mlu_uint8
313,no,,test_clamp_min_inplace_mlu_float16
314,no,,test_clamp_min_inplace_mlu_float32
315,no,,test_clamp_min_inplace_mlu_float64
316,no,,test_clamp_min_inplace_mlu_int16
317,no,,test_clamp_min_inplace_mlu_int32
318,no,,test_clamp_min_inplace_mlu_int64
319,no,,test_clamp_min_inplace_mlu_int8
320,no,,test_clamp_min_inplace_mlu_uint8
321,no,,test_clamp_min_mlu_float16
322,no,,test_clamp_min_mlu_float32
323,no,,test_clamp_min_mlu_float64
324,no,,test_clamp_min_mlu_int16
325,no,,test_clamp_min_mlu_int32
326,no,,test_clamp_min_mlu_int64
327,no,,test_clamp_min_mlu_int8
328,no,,test_clamp_min_mlu_uint8
329,no,,test_clamp_neg_mlu_float16
330,no,,test_clamp_neg_mlu_float32
331,no,,test_clamp_neg_mlu_float64
332,no,,test_clamp_neg_mlu_int16
333,no,,test_clamp_neg_mlu_int32
334,no,,test_clamp_neg_mlu_int64
335,no,,test_clamp_neg_mlu_int8
336,no,,test_clamp_pos_mlu_uint8
337,no,,test_clone_mlu_float16
338,no,,test_clone_mlu_float32
339,no,,test_clone_mlu_float64
340,no,,test_clone_mlu_int16
341,no,,test_clone_mlu_int32
342,no,,test_clone_mlu_int64
343,no,,test_clone_mlu_int8
344,no,,test_clone_mlu_uint8
345,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_float32
346,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_float64
347,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_int16
348,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_int32
349,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_int64
350,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_int8
351,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_conj_mlu_uint8
352,no,,test_contiguous_mlu_float16
353,no,,test_contiguous_mlu_float32
354,no,,test_contiguous_mlu_float64
355,no,,test_contiguous_mlu_int16
356,no,,test_contiguous_mlu_int32
357,no,,test_contiguous_mlu_int64
358,no,,test_contiguous_mlu_int8
359,no,,test_contiguous_mlu_uint8
360,no,,test_cos_inplace_mlu_float16
361,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 5 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 5.841255187988281e-05 (-0.9222255945205688 vs. -0.922167181968689), which occurred at index (2, 1, 3).
",test_cos_inplace_mlu_float32
362,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 5 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 8.280901410129271e-05 (-0.9898519101569846 vs. -0.9897691011428833), which occurred at index (4, 0, 2).
",test_cos_inplace_mlu_float64
363,no,,test_cos_mlu_float16
364,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 6 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 4.6133995056152344e-05 (-0.917746901512146 vs. -0.9177007675170898), which occurred at index (2, 4, 4).
",test_cos_mlu_float32
365,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 9 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.4100454822085773e-05 (0.540755365274921 vs. 0.5407412648200989), which occurred at index (2, 1, 4).
",test_cos_mlu_float64
366,yes,"<class 'RuntimeError'> : ""cosh_cpu"" not implemented for 'Half'
",test_cosh_inplace_mlu_float16
367,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_cosh_inplace_mlu_float32
368,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_cosh_inplace_mlu_float64
369,yes,"<class 'RuntimeError'> : ""cosh_cpu"" not implemented for 'Half'
",test_cosh_mlu_float16
370,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_cosh_mlu_float32
371,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_cosh_mlu_float64
372,yes,"<class 'RuntimeError'> : ""cross"" not implemented for 'Half'
",test_cross_mlu_float16
373,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_float32
374,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_float64
375,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_int16
376,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_int32
377,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_int64
378,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_int8
379,yes,"<class 'RuntimeError'> : cross only supports CPU and CUDA devices, out got: mlu
",test_cross_mlu_uint8
380,yes,"<class 'RuntimeError'> : ""cummax_cpu"" not implemented for 'Half'
",test_cummax_mlu_float16
381,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_float32
382,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_float64
383,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_int16
384,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_int32
385,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_int64
386,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_int8
387,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_mlu_uint8
388,yes,"<class 'RuntimeError'> : ""cummax_cpu"" not implemented for 'Half'
",test_cummax_neg_dim_mlu_float16
389,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_float32
390,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_float64
391,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_int16
392,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_int32
393,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_int64
394,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_int8
395,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummax_helper' with arguments from the 'MLU' backend. 'aten::_cummax_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummax_neg_dim_mlu_uint8
396,yes,"<class 'RuntimeError'> : ""cummin_cpu"" not implemented for 'Half'
",test_cummin_mlu_float16
397,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_float32
398,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_float64
399,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_int16
400,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_int32
401,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_int64
402,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_int8
403,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_mlu_uint8
404,yes,"<class 'RuntimeError'> : ""cummin_cpu"" not implemented for 'Half'
",test_cummin_neg_dim_mlu_float16
405,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_float32
406,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_float64
407,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_int16
408,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_int32
409,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_int64
410,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_int8
411,yes,"<class 'RuntimeError'> : Could not run 'aten::_cummin_helper' with arguments from the 'MLU' backend. 'aten::_cummin_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cummin_neg_dim_mlu_uint8
412,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_cumprod_mlu_complex128
413,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_cumprod_mlu_complex64
414,yes,"<class 'RuntimeError'> : ""cumprod_out_cpu"" not implemented for 'Half'
",test_cumprod_mlu_float16
415,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_mlu_float32
416,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_mlu_float64
417,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_mlu_int16
418,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_mlu_int32
419,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_mlu_int64
420,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_mlu_int8
421,yes,"<class 'RuntimeError'> : copy tensor from mlu:0 to mlu:0 failed!
[ERROR][/projs/framework/gaosongyun/catch/torch_mlu/csrc/aten/operators/cnnl/internal/cast_internal.cpp][line: 73][cnnl_cast_internal][thread:140165679527680][process:202481]: 
CNNL don't support cast unsigned char data type to long int data type!!
",test_cumprod_mlu_uint8
422,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_cumprod_neg_dim_mlu_complex128
423,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_cumprod_neg_dim_mlu_complex64
424,yes,"<class 'RuntimeError'> : ""cumprod_out_cpu"" not implemented for 'Half'
",test_cumprod_neg_dim_mlu_float16
425,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_neg_dim_mlu_float32
426,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_neg_dim_mlu_float64
427,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_neg_dim_mlu_int16
428,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_neg_dim_mlu_int32
429,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_neg_dim_mlu_int64
430,yes,"<class 'RuntimeError'> : Could not run 'aten::_cumprod' with arguments from the 'MLU' backend. 'aten::_cumprod' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_cumprod_neg_dim_mlu_int8
431,yes,"<class 'RuntimeError'> : copy tensor from mlu:0 to mlu:0 failed!
[ERROR][/projs/framework/gaosongyun/catch/torch_mlu/csrc/aten/operators/cnnl/internal/cast_internal.cpp][line: 73][cnnl_cast_internal][thread:140165679527680][process:202481]: 
CNNL don't support cast unsigned char data type to long int data type!!
",test_cumprod_neg_dim_mlu_uint8
432,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_cumsum_mlu_complex128
433,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_cumsum_mlu_complex64
434,no,,test_cumsum_mlu_float16
435,no,,test_cumsum_mlu_float32
436,no,,test_cumsum_mlu_float64
437,no,,test_cumsum_mlu_int16
438,no,,test_cumsum_mlu_int32
439,no,,test_cumsum_mlu_int64
440,no,,test_cumsum_mlu_int8
441,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 116 different element(s) (out of 125), with the greatest difference of 29 (30 vs. 1) occuring at index (2, 4, 1).
",test_cumsum_mlu_uint8
442,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_cumsum_neg_dim_mlu_complex128
443,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_cumsum_neg_dim_mlu_complex64
444,no,,test_cumsum_neg_dim_mlu_float16
445,no,,test_cumsum_neg_dim_mlu_float32
446,no,,test_cumsum_neg_dim_mlu_float64
447,no,,test_cumsum_neg_dim_mlu_int16
448,no,,test_cumsum_neg_dim_mlu_int32
449,no,,test_cumsum_neg_dim_mlu_int64
450,no,,test_cumsum_neg_dim_mlu_int8
451,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 118 different element(s) (out of 125), with the greatest difference of 37 (38 vs. 1) occuring at index (0, 1, 4).
",test_cumsum_neg_dim_mlu_uint8
452,no,,test_deg2rad_inplace_mlu_float16
453,no,,test_deg2rad_inplace_mlu_float32
454,no,,test_deg2rad_inplace_mlu_float64
455,no,,test_deg2rad_mlu_float16
456,no,,test_deg2rad_mlu_float32
457,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 63 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.634087845747313 (0.0014281720565173677 vs. -2.632659673690796), which occurred at index (4, 2, 3).
",test_deg2rad_mlu_float64
458,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_digamma_inplace_op_mlu_float32
459,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_digamma_inplace_op_mlu_float64
460,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_digamma_op_mlu_float32
461,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_digamma_op_mlu_float64
462,no,,test_dim_mlu_float16
463,no,,test_dim_mlu_float32
464,no,,test_dim_mlu_float64
465,no,,test_dim_mlu_int16
466,no,,test_dim_mlu_int32
467,no,,test_dim_mlu_int64
468,no,,test_dim_mlu_int8
469,no,,test_dim_mlu_uint8
470,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.960801601409912 (6.757948398590088 vs. 8.71875), which occurred at index 0.
",test_dist_2_5_norm_mlu_float16
471,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.1849803924560547 (4.132383346557617 vs. 5.317363739013672), which occurred at index 0.
",test_dist_2_5_norm_mlu_float32
472,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.7369255375042094 (6.726674621187197 vs. 8.463600158691406), which occurred at index 0.
",test_dist_2_5_norm_mlu_float64
473,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.107700824737549 (4.142299175262451 vs. 6.25), which occurred at index 0.
",test_dist_3_norm_mlu_float16
474,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.8563041687011719 (3.4850034713745117 vs. 5.341307640075684), which occurred at index 0.
",test_dist_3_norm_mlu_float32
475,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.8909428547113114 (4.444753365686638 vs. 6.335696220397949), which occurred at index 0.
",test_dist_3_norm_mlu_float64
476,no,,test_dist_mlu_float16
477,yes," <class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 8.821487426757812e-05 (7.9438652992248535 vs. 7.943777084350586), which occurred at index 0.",test_dist_mlu_float32
478,yes," <class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 8.821487426757812e-05 (7.9438652992248535 vs. 7.943777084350586), which occurred at index 0.",test_dist_mlu_float64
479,no,,test_div_inplace_mlu_float16
480,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 46 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.0159950256347656e-05 (0.9146247506141663 vs. 0.9146549105644226), which occurred at index (4, 4, 3).
",test_div_inplace_mlu_float32
481,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 47 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.4107327762701303e-05 (-0.7310370532366599 vs. -0.7310611605644226), which occurred at index (1, 1, 2).
",test_div_inplace_mlu_float64
482,no,,test_div_inplace_tensor_mlu_float16
483,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 84 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.02435302734375 (651.24169921875 vs. 651.2173461914062), which occurred at index (4, 2, 1).
",test_div_inplace_tensor_mlu_float32
484,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 9 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.4735781576291629e-05 (-269.03578238335905 vs. -269.0357971191406), which occurred at index (2, 4, 3).
",test_div_inplace_tensor_mlu_float64
485,no,,test_div_mlu_float16
486,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 46 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.063678741455078e-05 (-0.9290522336959839 vs. -0.9290828704833984), which occurred at index (3, 4, 0).
",test_div_mlu_float32
487,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 40 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.6442029445128412e-05 (-0.8017558679795576 vs. -0.8017823100090027), which occurred at index (1, 1, 4).
",test_div_mlu_float64
488,no,,test_div_tensor_mlu_float16
489,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 92 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.029541015625 (790.8116455078125 vs. 790.7821044921875), which occurred at index (2, 1, 0).
",test_div_tensor_mlu_float32
490,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 7 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.7421871550359356e-05 (-637.3782012499966 vs. -637.378173828125), which occurred at index (3, 2, 4).
",test_div_tensor_mlu_float64
491,yes,"<class 'RuntimeError'> : Could not run 'aten::dot' with arguments from the 'MLU' backend. 'aten::dot' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer, Autocast].
",test_dot_mlu_float16
492,yes,"<class 'RuntimeError'> : Could not run 'aten::dot' with arguments from the 'MLU' backend. 'aten::dot' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer, Autocast].
",test_dot_mlu_float32
493,yes,"<class 'RuntimeError'> : Could not run 'aten::dot' with arguments from the 'MLU' backend. 'aten::dot' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer, Autocast].
",test_dot_mlu_float64
494,yes,"<class 'RuntimeError'> : Could not run 'aten::eig' with arguments from the 'MLU' backend. 'aten::eig' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_eig_with_eigvec_mlu_float32
495,yes,"<class 'RuntimeError'> : Could not run 'aten::eig' with arguments from the 'MLU' backend. 'aten::eig' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_eig_with_eigvec_mlu_float64
496,no,,test_element_size_mlu_float32
497,no,,test_element_size_mlu_float64
498,no,,test_eq_equal_mlu_float16
499,no,,test_eq_equal_mlu_float32
500,no,,test_eq_equal_mlu_float64
501,no,,test_eq_equal_mlu_int16
502,no,,test_eq_equal_mlu_int32
503,no,,test_eq_equal_mlu_int64
504,no,,test_eq_equal_mlu_int8
505,no,,test_eq_equal_mlu_uint8
506,no,,test_eq_inplace_equal_mlu_float16
507,no,,test_eq_inplace_equal_mlu_float32
508,no,,test_eq_inplace_equal_mlu_float64
509,no,,test_eq_inplace_equal_mlu_int16
510,no,,test_eq_inplace_equal_mlu_int32
511,no,,test_eq_inplace_equal_mlu_int64
512,no,,test_eq_inplace_equal_mlu_int8
513,no,,test_eq_inplace_equal_mlu_uint8
514,no,,test_eq_inplace_mlu_float16
515,no,,test_eq_inplace_mlu_float32
516,no,,test_eq_inplace_mlu_float64
517,no,,test_eq_inplace_mlu_int16
518,no,,test_eq_inplace_mlu_int32
519,no,,test_eq_inplace_mlu_int64
520,no,,test_eq_inplace_mlu_int8
521,no,,test_eq_inplace_mlu_uint8
522,no,,test_eq_mlu_float16
523,no,,test_eq_mlu_float32
524,no,,test_eq_mlu_float64
525,no,,test_eq_mlu_int16
526,no,,test_eq_mlu_int32
527,no,,test_eq_mlu_int64
528,no,,test_eq_mlu_int8
529,no,,test_eq_mlu_uint8
530,no,,test_equal_equal_mlu_float16
531,no,,test_equal_equal_mlu_float32
532,no,,test_equal_equal_mlu_float64
533,no,,test_equal_equal_mlu_int16
534,no,,test_equal_equal_mlu_int32
535,no,,test_equal_equal_mlu_int64
536,no,,test_equal_equal_mlu_int8
537,no,,test_equal_equal_mlu_uint8
538,no,,test_equal_mlu_float16
539,no,,test_equal_mlu_float32
540,no,,test_equal_mlu_float64
541,no,,test_equal_mlu_int16
542,no,,test_equal_mlu_int32
543,no,,test_equal_mlu_int64
544,no,,test_equal_mlu_int8
545,no,,test_equal_mlu_uint8
546,no,,test_erf_inplace_mlu_float16
547,no,,test_erf_inplace_mlu_float32
548,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/erf_internel.cpp][line: 12][cnnl_erf_internal][thread:140219569719040][process:16986]: 
erf support half/float
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1533][erf_][thread:140219569719040][process:16986]: OpMethods::erf_ Op running on CPU!
",test_erf_inplace_mlu_float64
549,no,,test_erf_mlu_float16
550,no,,test_erf_mlu_float32
551,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/erf_internel.cpp][line: 12][cnnl_erf_internal][thread:140219569719040][process:16986]: 
erf support half/float
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1526][erf][thread:140219569719040][process:16986]: OpMethods::erf Op running on CPU!
",test_erf_mlu_float64
552,yes,"<class 'RuntimeError'> : erfc_vml_cpu not implemented for 'Half'
",test_erfc_inplace_mlu_float16
553,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_erfc_inplace_mlu_float32
554,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_erfc_inplace_mlu_float64
555,yes,"<class 'RuntimeError'> : erfc_vml_cpu not implemented for 'Half'
",test_erfc_mlu_float16
556,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_erfc_mlu_float32
557,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_erfc_mlu_float64
558,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 1 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.01714324951171875 (42.10785675048828 vs. 42.125), which occurred at index (2, 4, 3).
",test_exp_inplace_mlu_float16
559,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 122 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0024871826171875 (19.070037841796875 vs. 19.072525024414062), which occurred at index (1, 3, 1).
",test_exp_inplace_mlu_float32
560,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 122 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.001649238665797803 (5.934141300122044 vs. 5.935790538787842), which occurred at index (3, 0, 2).
",test_exp_inplace_mlu_float64
561,no,,test_exp_inplace_small_mlu_float16
562,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 121 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0011742115020751953 (2.5538365840911865 vs. 2.5526623725891113), which occurred at index (2, 0, 3).
",test_exp_inplace_small_mlu_float32
563,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 125 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0009715773294245444 (2.5417425848672663 vs. 2.540771007537842), which occurred at index (2, 1, 0).
",test_exp_inplace_small_mlu_float64
564,no,,test_exp_mlu_float16
565,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 120 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0020971298217773438 (8.4791841506958 vs. 8.481281280517578), which occurred at index (0, 0, 1).
",test_exp_mlu_float32
566,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 122 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0019732524320215106 (4.488577466146621 vs. 4.4866042137146), which occurred at index (3, 1, 4).
",test_exp_mlu_float64
567,no,,test_exp_small_mlu_float16
568,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 121 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.00103759765625 (2.5630476474761963 vs. 2.5620100498199463), which occurred at index (2, 1, 0).
",test_exp_small_mlu_float32
569,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 123 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.001049132617483739 (2.5475409939608675 vs. 2.546491861343384), which occurred at index (0, 1, 2).
",test_exp_small_mlu_float64
570,no,,test_expand_as_mlu_float16
571,no,,test_expand_as_mlu_float32
572,no,,test_expand_as_mlu_float64
573,no,,test_expand_as_mlu_int16
574,no,,test_expand_as_mlu_int32
575,no,,test_expand_as_mlu_int64
576,no,,test_expand_as_mlu_int8
577,no,,test_expand_as_mlu_uint8
578,no,,test_expand_mlu_float16
579,no,,test_expand_mlu_float32
580,no,,test_expand_mlu_float64
581,no,,test_expand_mlu_int16
582,no,,test_expand_mlu_int32
583,no,,test_expand_mlu_int64
584,no,,test_expand_mlu_int8
585,no,,test_expand_mlu_uint8
586,yes,"<class 'RuntimeError'> : expm1_vml_cpu not implemented for 'Half'
",test_expm1_inplace_mlu_float16
587,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_inplace_mlu_float32
588,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_inplace_mlu_float64
589,yes,"<class 'RuntimeError'> : expm1_vml_cpu not implemented for 'Half'
",test_expm1_inplace_small_mlu_float16
590,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_inplace_small_mlu_float32
591,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_inplace_small_mlu_float64
592,yes,"<class 'RuntimeError'> : expm1_vml_cpu not implemented for 'Half'
",test_expm1_mlu_float16
593,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_mlu_float32
594,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_mlu_float64
595,yes,"<class 'RuntimeError'> : expm1_vml_cpu not implemented for 'Half'
",test_expm1_small_mlu_float16
596,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_small_mlu_float32
597,yes,"<class 'RuntimeError'> : Could not run 'aten::expm1.out' with arguments from the 'MLU' backend. 'aten::expm1.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_expm1_small_mlu_float64
598,no,,test_fill__mlu_float16
599,no,,test_fill__mlu_float32
600,no,,test_fill__mlu_float64
601,no,,test_fill__mlu_int16
602,no,,test_fill__mlu_int32
603,no,,test_fill__mlu_int64
604,no,,test_fill__mlu_int8
605,no,,test_fill__mlu_uint8
606,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_flip_d02_mlu_complex128
607,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_flip_d02_mlu_complex64
608,no,,test_flip_d02_mlu_float16
609,no,,test_flip_d02_mlu_float32
610,no,,test_flip_d02_mlu_float64
611,no,,test_flip_d02_mlu_int16
612,no,,test_flip_d02_mlu_int32
613,no,,test_flip_d02_mlu_int64
614,no,,test_flip_d02_mlu_int8
615,no,,test_flip_d02_mlu_uint8
616,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_flip_d0_mlu_complex128
617,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_flip_d0_mlu_complex64
618,no,,test_flip_d0_mlu_float16
619,no,,test_flip_d0_mlu_float32
620,no,,test_flip_d0_mlu_float64
621,no,,test_flip_d0_mlu_int16
622,no,,test_flip_d0_mlu_int32
623,no,,test_flip_d0_mlu_int64
624,no,,test_flip_d0_mlu_int8
625,no,,test_flip_d0_mlu_uint8
626,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_flip_d20_mlu_complex128
627,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_flip_d20_mlu_complex64
628,no,,test_flip_d20_mlu_float16
629,no,,test_flip_d20_mlu_float32
630,no,,test_flip_d20_mlu_float64
631,no,,test_flip_d20_mlu_int16
632,no,,test_flip_d20_mlu_int32
633,no,,test_flip_d20_mlu_int64
634,no,,test_flip_d20_mlu_int8
635,no,,test_flip_d20_mlu_uint8
636,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_flip_neg_d_mlu_complex128
637,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_flip_neg_d_mlu_complex64
638,no,,test_flip_neg_d_mlu_float16
639,no,,test_flip_neg_d_mlu_float32
640,no,,test_flip_neg_d_mlu_float64
641,no,,test_flip_neg_d_mlu_int16
642,no,,test_flip_neg_d_mlu_int32
643,no,,test_flip_neg_d_mlu_int64
644,no,,test_flip_neg_d_mlu_int8
645,no,,test_flip_neg_d_mlu_uint8
646,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_float16
647,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_float32
648,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_float64
649,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_int16
650,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_int32
651,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_int64
652,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_int8
653,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_inplace_mlu_uint8
654,yes,"<class 'RuntimeError'> : trunc_vml_cpu not implemented for 'Half'
",test_floor_divide_inplace_tensor_mlu_float16
655,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_float32
656,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_float64
657,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_int16
658,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_int32
659,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_int64
660,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_int8
661,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::floor_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_inplace_tensor_mlu_uint8
662,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_float16
663,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_float32
664,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_float64
665,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_int16
666,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_int32
667,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_int64
668,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_int8
669,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_floor_divide_mlu_uint8
670,yes,"<class 'RuntimeError'> : trunc_vml_cpu not implemented for 'Half'
",test_floor_divide_tensor_mlu_float16
671,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide' with arguments from the 'MLU' backend. 'aten::floor_divide' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_tensor_mlu_float32
672,yes,"<class 'RuntimeError'> : Could not run 'aten::floor_divide' with arguments from the 'MLU' backend. 'aten::floor_divide' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_floor_divide_tensor_mlu_float64
673,no,,test_floor_inplace_mlu_float16
674,no,,test_floor_inplace_mlu_float32
675,no,,test_floor_inplace_mlu_float64
676,no,,test_floor_mlu_float16
677,no,,test_floor_mlu_float32
678,no,,test_floor_mlu_float64
679,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_float16
680,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_float32
681,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_float64
682,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_int16
683,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_int32
684,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_int64
685,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_int8
686,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Tensor' with arguments from the 'MLU' backend. 'aten::fmod_.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_tensor_mlu_uint8
687,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_float16
688,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_float32
689,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_float64
690,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_int16
691,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_int32
692,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_int64
693,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_int8
694,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod_.Scalar' with arguments from the 'MLU' backend. 'aten::fmod_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_inplace_value_mlu_uint8
695,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_float16
696,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_float32
697,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_float64
698,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_int16
699,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_int32
700,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_int64
701,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_int8
702,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Tensor' with arguments from the 'MLU' backend. 'aten::fmod.Tensor' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_tensor_mlu_uint8
703,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_float16
704,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_float32
705,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_float64
706,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_int16
707,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_int32
708,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_int64
709,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_int8
710,yes,"<class 'RuntimeError'> : Could not run 'aten::fmod.Scalar' with arguments from the 'MLU' backend. 'aten::fmod.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_fmod_value_mlu_uint8
711,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_frac_inplace_mlu_float16
712,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_frac_inplace_mlu_float32
713,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_frac_inplace_mlu_float64
714,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_frac_mlu_float16
715,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_frac_mlu_float32
716,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_frac_mlu_float64
717,no,,test_ge_inplace_mlu_float16
718,no,,test_ge_inplace_mlu_float32
719,no,,test_ge_inplace_mlu_float64
720,no,,test_ge_inplace_mlu_int16
721,no,,test_ge_inplace_mlu_int32
722,no,,test_ge_inplace_mlu_int64
723,no,,test_ge_inplace_mlu_int8
724,no,,test_ge_inplace_mlu_uint8
725,no,,test_ge_mlu_float16
726,no,,test_ge_mlu_float32
727,no,,test_ge_mlu_float64
728,no,,test_ge_mlu_int16
729,no,,test_ge_mlu_int32
730,no,,test_ge_mlu_int64
731,no,,test_ge_mlu_int8
732,no,,test_ge_mlu_uint8
733,yes,"<class 'RuntimeError'> : Could not run 'aten::geqrf' with arguments from the 'MLU' backend. 'aten::geqrf' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_geqrf_mlu_float32
734,yes,"<class 'RuntimeError'> : Could not run 'aten::geqrf' with arguments from the 'MLU' backend. 'aten::geqrf' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_geqrf_mlu_float64
735,no,,test_gt_inplace_mlu_float16
736,no,,test_gt_inplace_mlu_float32
737,no,,test_gt_inplace_mlu_float64
738,no,,test_gt_inplace_mlu_int16
739,no,,test_gt_inplace_mlu_int32
740,no,,test_gt_inplace_mlu_int64
741,no,,test_gt_inplace_mlu_int8
742,no,,test_gt_inplace_mlu_uint8
743,no,,test_gt_mlu_float16
744,no,,test_gt_mlu_float32
745,no,,test_gt_mlu_float64
746,no,,test_gt_mlu_int16
747,no,,test_gt_mlu_int32
748,no,,test_gt_mlu_int64
749,no,,test_gt_mlu_int8
750,no,,test_gt_mlu_uint8
751,no,,test_is_contiguous_mlu_float16
752,no,,test_is_contiguous_mlu_float32
753,no,,test_is_contiguous_mlu_float64
754,no,,test_is_contiguous_mlu_int16
755,no,,test_is_contiguous_mlu_int32
756,no,,test_is_contiguous_mlu_int64
757,no,,test_is_contiguous_mlu_int8
758,no,,test_is_contiguous_mlu_uint8
759,no,,test_is_same_size_negative_mlu_float16
760,no,,test_is_same_size_negative_mlu_float32
761,no,,test_is_same_size_negative_mlu_float64
762,no,,test_is_same_size_negative_mlu_int16
763,no,,test_is_same_size_negative_mlu_int32
764,no,,test_is_same_size_negative_mlu_int64
765,no,,test_is_same_size_negative_mlu_int8
766,no,,test_is_same_size_negative_mlu_uint8
767,no,,test_is_same_size_positive_mlu_float16
768,no,,test_is_same_size_positive_mlu_float32
769,no,,test_is_same_size_positive_mlu_float64
770,no,,test_is_same_size_positive_mlu_int16
771,no,,test_is_same_size_positive_mlu_int32
772,no,,test_is_same_size_positive_mlu_int64
773,no,,test_is_same_size_positive_mlu_int8
774,no,,test_is_same_size_positive_mlu_uint8
775,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_float16
776,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_float32
777,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_float64
778,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_int16
779,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_int32
780,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_int64
781,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_int8
782,yes,"<class 'RuntimeError'> : Could not run 'aten::is_set_to' with arguments from the 'MLU' backend. 'aten::is_set_to' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_is_set_to_mlu_uint8
783,no,,test_kthvalue_dim_mlu_float16
784,no,,test_kthvalue_dim_mlu_float32
785,no,,test_kthvalue_dim_mlu_float64
786,no,,test_kthvalue_dim_mlu_int16
787,no,,test_kthvalue_dim_mlu_int32
788,no,,test_kthvalue_dim_mlu_int64
789,no,,test_kthvalue_dim_mlu_int8
790,no,,test_kthvalue_dim_mlu_uint8
791,no,,test_kthvalue_mlu_float16
792,no,,test_kthvalue_mlu_float32
793,no,,test_kthvalue_mlu_float64
794,no,,test_kthvalue_mlu_int16
795,no,,test_kthvalue_mlu_int32
796,no,,test_kthvalue_mlu_int64
797,no,,test_kthvalue_mlu_int8
798,no,,test_kthvalue_mlu_uint8
799,no,,test_kthvalue_neg_dim_mlu_float16
800,no,,test_kthvalue_neg_dim_mlu_float32
801,no,,test_kthvalue_neg_dim_mlu_float64
802,no,,test_kthvalue_neg_dim_mlu_int16
803,no,,test_kthvalue_neg_dim_mlu_int32
804,no,,test_kthvalue_neg_dim_mlu_int64
805,no,,test_kthvalue_neg_dim_mlu_int8
806,no,,test_kthvalue_neg_dim_mlu_uint8
807,no,,test_le_inplace_mlu_float16
808,no,,test_le_inplace_mlu_float32
809,no,,test_le_inplace_mlu_float64
810,no,,test_le_inplace_mlu_int16
811,no,,test_le_inplace_mlu_int32
812,no,,test_le_inplace_mlu_int64
813,no,,test_le_inplace_mlu_int8
814,no,,test_le_inplace_mlu_uint8
815,no,,test_le_mlu_float16
816,no,,test_le_mlu_float32
817,no,,test_le_mlu_float64
818,no,,test_le_mlu_int16
819,no,,test_le_mlu_int32
820,no,,test_le_mlu_int64
821,no,,test_le_mlu_int8
822,no,,test_le_mlu_uint8
823,yes,"<class 'RuntimeError'> : Could not run 'aten::lerp_.Scalar' with arguments from the 'MLU' backend. 'aten::lerp_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_lerp_inplace_mlu_float32
824,yes,"<class 'RuntimeError'> : Could not run 'aten::lerp_.Scalar' with arguments from the 'MLU' backend. 'aten::lerp_.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_lerp_inplace_mlu_float64
825,yes,"<class 'RuntimeError'> : Could not run 'aten::lerp.Scalar' with arguments from the 'MLU' backend. 'aten::lerp.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_lerp_mlu_float32
826,yes,"<class 'RuntimeError'> : Could not run 'aten::lerp.Scalar' with arguments from the 'MLU' backend. 'aten::lerp.Scalar' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_lerp_mlu_float64
827,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_lgamma_inplace_mlu_float32
828,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_lgamma_inplace_mlu_float64
829,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma' with arguments from the 'MLU' backend. 'aten::lgamma' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_lgamma_mlu_float32
830,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.0029372337960751e-05 (5.349116818007592 vs. 5.349106788635254), which occurred at index (4, 4, 2).
",test_lgamma_mlu_float64
831,yes,"<class 'RuntimeError'> : log10_vml_cpu not implemented for 'Half'
",test_log10_inplace_mlu_float16
832,yes,"<class 'RuntimeError'> : Could not run 'aten::log10.out' with arguments from the 'MLU' backend. 'aten::log10.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_log10_inplace_mlu_float32
833,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_log10_inplace_mlu_float64
834,yes,"<class 'RuntimeError'> : log10_vml_cpu not implemented for 'Half'
",test_log10_mlu_float16
835,yes,"<class 'RuntimeError'> : Could not run 'aten::log10.out' with arguments from the 'MLU' backend. 'aten::log10.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_log10_mlu_float32
836,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_log10_mlu_float64
837,yes,"<class 'RuntimeError'> : Could not run 'aten::log1p_' with arguments from the 'MLU' backend. 'aten::log1p_' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_log1p_inplace_mlu_float32
838,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_log1p_inplace_mlu_float64
839,yes,"<class 'RuntimeError'> : Could not run 'aten::log1p.out' with arguments from the 'MLU' backend. 'aten::log1p.out' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_log1p_mlu_float32
840,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_log1p_mlu_float64
841,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 53 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 53 nan comparisons). The greatest difference was nan (nan vs. -25.796875), which occurred at index (0, 0, 3).
",test_log2_inplace_mlu_float16
842,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 73 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 67 nan comparisons). The greatest difference was nan (nan vs. -65.65458679199219), which occurred at index (0, 0, 1).
",test_log2_inplace_mlu_float32
843,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 74 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 62 nan comparisons). The greatest difference was nan (nan vs. -65.65458679199219), which occurred at index (0, 0, 1).
",test_log2_inplace_mlu_float64
844,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 54 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 54 nan comparisons). The greatest difference was nan (nan vs. -25.796875), which occurred at index (0, 0, 1).
",test_log2_mlu_float16
845,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 77 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 60 nan comparisons). The greatest difference was nan (nan vs. -65.65458679199219), which occurred at index (0, 0, 2).
",test_log2_mlu_float32
846,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 73 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 61 nan comparisons). The greatest difference was nan (nan vs. -65.65458679199219), which occurred at index (0, 0, 1).
",test_log2_mlu_float64
847,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 69 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 69 nan comparisons). The greatest difference was nan (nan vs. -17.875), which occurred at index (0, 0, 1).
",test_log_inplace_mlu_float16
848,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 76 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 68 nan comparisons). The greatest difference was nan (nan vs. -45.50829315185547), which occurred at index (0, 0, 0).
",test_log_inplace_mlu_float32
849,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 125 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 66 nan comparisons). The greatest difference was nan (nan vs. -0.6756665110588074), which occurred at index (0, 0, 0).
cnnl_log_ not implemented for Double
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2607][log_][thread:140219569719040][process:16986]: OpMethods::log_ Op running on CPU!
",test_log_inplace_mlu_float64
850,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 60 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 60 nan comparisons). The greatest difference was nan (nan vs. -17.875), which occurred at index (0, 0, 0).
",test_log_mlu_float16
851,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 70 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 64 nan comparisons). The greatest difference was nan (nan vs. -45.50829315185547), which occurred at index (0, 0, 2).
",test_log_mlu_float32
852,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
cnnl_log not implemented for Double
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2600][log][thread:140219569719040][process:16986]: OpMethods::log Op running on CPU!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_log_mlu_float64
853,yes,"<class 'RuntimeError'> : ""logcumsumexp_out_cpu"" not implemented for 'Half'
",test_logcumsumexp_mlu_float16
854,yes,"<class 'RuntimeError'> : Could not run 'aten::_logcumsumexp' with arguments from the 'MLU' backend. 'aten::_logcumsumexp' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_logcumsumexp_mlu_float32
855,yes,"<class 'RuntimeError'> : Could not run 'aten::_logcumsumexp' with arguments from the 'MLU' backend. 'aten::_logcumsumexp' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_logcumsumexp_mlu_float64
856,yes,"<class 'RuntimeError'> : ""logcumsumexp_out_cpu"" not implemented for 'Half'
",test_logcumsumexp_neg_dim_mlu_float16
857,yes,"<class 'RuntimeError'> : Could not run 'aten::_logcumsumexp' with arguments from the 'MLU' backend. 'aten::_logcumsumexp' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_logcumsumexp_neg_dim_mlu_float32
858,yes,"<class 'RuntimeError'> : Could not run 'aten::_logcumsumexp' with arguments from the 'MLU' backend. 'aten::_logcumsumexp' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_logcumsumexp_neg_dim_mlu_float64
859,no,,test_lt_inplace_mlu_float16
860,no,,test_lt_inplace_mlu_float32
861,no,,test_lt_inplace_mlu_float64
862,no,,test_lt_inplace_mlu_int16
863,no,,test_lt_inplace_mlu_int32
864,no,,test_lt_inplace_mlu_int64
865,no,,test_lt_inplace_mlu_int8
866,no,,test_lt_inplace_mlu_uint8
867,no,,test_lt_mlu_float16
868,no,,test_lt_mlu_float32
869,no,,test_lt_mlu_float64
870,no,,test_lt_mlu_int16
871,no,,test_lt_mlu_int32
872,no,,test_lt_mlu_int64
873,no,,test_lt_mlu_int8
874,no,,test_lt_mlu_uint8
875,no,,test_max_dim_mlu_float16
876,no,,test_max_dim_mlu_float32
877,no,,test_max_dim_mlu_float64
878,no,,test_max_dim_mlu_int16
879,no,,test_max_dim_mlu_int32
880,no,,test_max_dim_mlu_int64
881,no,,test_max_dim_mlu_int8
882,no,,test_max_dim_mlu_uint8
883,no,,test_max_elementwise_mlu_float16
884,no,,test_max_elementwise_mlu_float32
885,no,,test_max_elementwise_mlu_float64
886,yes,"[2021-7-16 17:36:49] [CNNL] [Error]: [cnnlMaximum] Data type should be half, float or int32
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/maximum_internal.cpp][line: 50][cnnl_maximum_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1619][max][thread:140219569719040][process:16986]: OpMethods::max Op running on CPU!
",test_max_elementwise_mlu_int16
887,no,,test_max_elementwise_mlu_int32
888,no,,test_max_elementwise_mlu_int64
889,yes,"[2021-7-16 17:36:49] [CNNL] [Error]: [cnnlMaximum] Data type should be half, float or int32
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/maximum_internal.cpp][line: 50][cnnl_maximum_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1619][max][thread:140219569719040][process:16986]: OpMethods::max Op running on CPU!
",test_max_elementwise_mlu_int8
890,yes,"[2021-7-16 17:36:49] [CNNL] [Error]: [cnnlMaximum] Data type should be half, float or int32
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/maximum_internal.cpp][line: 50][cnnl_maximum_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1619][max][thread:140219569719040][process:16986]: OpMethods::max Op running on CPU!
",test_max_elementwise_mlu_uint8
891,no,,test_max_mlu_float16
892,no,,test_max_mlu_float32
893,no,,test_max_mlu_float64
894,no,,test_max_mlu_int16
895,no,,test_max_mlu_int32
896,no,,test_max_mlu_int64
897,no,,test_max_mlu_int8
898,no,,test_max_mlu_uint8
899,no,,test_max_neg_dim_mlu_float16
900,no,,test_max_neg_dim_mlu_float32
901,no,,test_max_neg_dim_mlu_float64
902,no,,test_max_neg_dim_mlu_int16
903,no,,test_max_neg_dim_mlu_int32
904,no,,test_max_neg_dim_mlu_int64
905,no,,test_max_neg_dim_mlu_int8
906,no,,test_max_neg_dim_mlu_uint8
907,yes,"<class 'unittest.case.SkipTest'> : test is slow; run with PYTORCH_TEST_WITH_SLOW to enable test
",test_mean_64bit_indexing_mlu_float64
908,no,,test_mean_dim_mlu_float16
909,no,,test_mean_dim_mlu_float32
910,no,,test_mean_dim_mlu_float64
911,no,,test_mean_mlu_float16
912,no,,test_mean_mlu_float32
913,no,,test_mean_mlu_float64
914,no,,test_mean_neg_dim_mlu_float16
915,no,,test_mean_neg_dim_mlu_float32
916,no,,test_mean_neg_dim_mlu_float64
917,no,,test_min_dim_mlu_float16
918,no,,test_min_dim_mlu_float32
919,no,,test_min_dim_mlu_float64
920,no,,test_min_dim_mlu_int16
921,no,,test_min_dim_mlu_int32
922,no,,test_min_dim_mlu_int64
923,no,,test_min_dim_mlu_int8
924,no,,test_min_dim_mlu_uint8
925,no,,test_min_elementwise_mlu_float16
926,no,,test_min_elementwise_mlu_float32
927,no,,test_min_elementwise_mlu_float64
928,yes,"[2021-7-16 17:36:49] [CNNL] [Error]: [cnnlMinimum] Data type should be half, float or int32
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/minimum_internal.cpp][line: 51][cnnl_minimum_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1684][min][thread:140219569719040][process:16986]: OpMethods::min Op running on CPU!
",test_min_elementwise_mlu_int16
929,no,,test_min_elementwise_mlu_int32
930,no,,test_min_elementwise_mlu_int64
931,yes,"[2021-7-16 17:36:49] [CNNL] [Error]: [cnnlMinimum] Data type should be half, float or int32
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/minimum_internal.cpp][line: 51][cnnl_minimum_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1684][min][thread:140219569719040][process:16986]: OpMethods::min Op running on CPU!
",test_min_elementwise_mlu_int8
932,yes,"[2021-7-16 17:36:49] [CNNL] [Error]: [cnnlMinimum] Data type should be half, float or int32
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/minimum_internal.cpp][line: 51][cnnl_minimum_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1684][min][thread:140219569719040][process:16986]: OpMethods::min Op running on CPU!
",test_min_elementwise_mlu_uint8
933,no,,test_min_mlu_float16
934,no,,test_min_mlu_float32
935,no,,test_min_mlu_float64
936,no,,test_min_mlu_int16
937,no,,test_min_mlu_int32
938,no,,test_min_mlu_int64
939,no,,test_min_mlu_int8
940,no,,test_min_mlu_uint8
941,no,,test_min_neg_dim_mlu_float16
942,no,,test_min_neg_dim_mlu_float32
943,no,,test_min_neg_dim_mlu_float64
944,no,,test_min_neg_dim_mlu_int16
945,no,,test_min_neg_dim_mlu_int32
946,no,,test_min_neg_dim_mlu_int64
947,no,,test_min_neg_dim_mlu_int8
948,no,,test_min_neg_dim_mlu_uint8
949,yes,"<class 'RuntimeError'> : _th_mode_out not supported on CPUType for Half
",test_mode_dim_mlu_float16
950,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_float32
951,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_float64
952,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_int16
953,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_int32
954,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_int64
955,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_int8
956,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_dim_mlu_uint8
957,yes,"<class 'RuntimeError'> : _th_mode_out not supported on CPUType for Half
",test_mode_mlu_float16
958,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_float32
959,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_float64
960,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_int16
961,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_int32
962,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_int64
963,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_int8
964,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_mlu_uint8
965,yes,"<class 'RuntimeError'> : _th_mode_out not supported on CPUType for Half
",test_mode_neg_dim_mlu_float16
966,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_float32
967,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_float64
968,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_int16
969,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_int32
970,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_int64
971,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_int8
972,yes,"<class 'RuntimeError'> : mode only supports CPU AND CUDA device type, got: mlu
",test_mode_neg_dim_mlu_uint8
973,no,,test_mul_inplace_mlu_float16
974,no,,test_mul_inplace_mlu_float32
975,no,,test_mul_inplace_mlu_float64
976,no,,test_mul_inplace_mlu_int16
977,no,,test_mul_inplace_mlu_int32
978,no,,test_mul_inplace_mlu_int64
979,no,,test_mul_inplace_mlu_int8
980,no,,test_mul_inplace_mlu_uint8
981,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 1 nan comparisons). The greatest difference was nan (-4.62109375 vs. nan), which occurred at index 0.
",test_mul_inplace_scalar_mlu_float16
982,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.9629452228546143 (0.9629452228546143 vs. 1.401298464324817e-45), which occurred at index 0.
",test_mul_inplace_scalar_mlu_float32
983,no,,test_mul_inplace_scalar_mlu_float64
984,no,,test_mul_inplace_scalar_mlu_int16
985,no,,test_mul_inplace_scalar_mlu_int32
986,no,,test_mul_inplace_scalar_mlu_int64
987,no,,test_mul_inplace_scalar_mlu_int8
988,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/cast_internal.cpp][line: 73][cnnl_cast_internal][thread:140219569719040][process:16986]: 
CNNL don't support cast int data type to unsigned char data type!!
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 963][mul_][thread:140219569719040][process:16986]: OpMethods::mul_ Op running on CPU!
",test_mul_inplace_scalar_mlu_uint8
989,no,,test_mul_inplace_tensor_mlu_float16
990,no,,test_mul_inplace_tensor_mlu_float32
991,no,,test_mul_inplace_tensor_mlu_float64
992,no,,test_mul_inplace_tensor_mlu_int16
993,no,,test_mul_inplace_tensor_mlu_int32
994,no,,test_mul_inplace_tensor_mlu_int64
995,no,,test_mul_inplace_tensor_mlu_int8
996,no,,test_mul_inplace_tensor_mlu_uint8
997,no,,test_mul_mlu_float16
998,no,,test_mul_mlu_float32
999,no,,test_mul_mlu_float64
1000,no,,test_mul_mlu_int16
1001,no,,test_mul_mlu_int32
1002,no,,test_mul_mlu_int64
1003,no,,test_mul_mlu_int8
1004,no,,test_mul_mlu_uint8
1005,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.01, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.4013671875 (-0.4013671875 vs. 0.0), which occurred at index 0.
",test_mul_scalar_mlu_float16
1006,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.29195111989974976 (-0.29195111989974976 vs. 0.0), which occurred at index 0.
",test_mul_scalar_mlu_float32
1007,no,,test_mul_scalar_mlu_float64
1008,no,,test_mul_scalar_mlu_int16
1009,no,,test_mul_scalar_mlu_int32
1010,no,,test_mul_scalar_mlu_int64
1011,no,,test_mul_scalar_mlu_int8
1012,no,,test_mul_scalar_mlu_uint8
1013,no,,test_mul_tensor_mlu_float16
1014,no,,test_mul_tensor_mlu_float32
1015,no,,test_mul_tensor_mlu_float64
1016,no,,test_mul_tensor_mlu_int16
1017,no,,test_mul_tensor_mlu_int32
1018,no,,test_mul_tensor_mlu_int64
1019,no,,test_mul_tensor_mlu_int8
1020,no,,test_mul_tensor_mlu_uint8
1021,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_2d_p=1_mlu_float32
1022,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_2d_p=1_mlu_float64
1023,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_2d_p=2_mlu_float32
1024,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_2d_p=2_mlu_float64
1025,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_inplace_2d_p=1_mlu_float32
1026,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_inplace_2d_p=1_mlu_float64
1027,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_inplace_2d_p=2_mlu_float32
1028,yes,"<class 'RuntimeError'> : Could not run 'aten::lgamma_' with arguments from the 'MLU' backend. 'aten::lgamma_' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_mvlgamma_inplace_2d_p=2_mlu_float64
1029,no,,test_narrow_mlu_float16
1030,no,,test_narrow_mlu_float32
1031,no,,test_narrow_mlu_float64
1032,no,,test_narrow_mlu_int16
1033,no,,test_narrow_mlu_int32
1034,no,,test_narrow_mlu_int64
1035,no,,test_narrow_mlu_int8
1036,no,,test_narrow_mlu_uint8
1037,no,,test_narrow_neg_dim_mlu_float16
1038,no,,test_narrow_neg_dim_mlu_float32
1039,no,,test_narrow_neg_dim_mlu_float64
1040,no,,test_narrow_neg_dim_mlu_int16
1041,no,,test_narrow_neg_dim_mlu_int32
1042,no,,test_narrow_neg_dim_mlu_int64
1043,no,,test_narrow_neg_dim_mlu_int8
1044,no,,test_narrow_neg_dim_mlu_uint8
1045,no,,test_ndimension_mlu_float16
1046,no,,test_ndimension_mlu_float32
1047,no,,test_ndimension_mlu_float64
1048,no,,test_ndimension_mlu_int16
1049,no,,test_ndimension_mlu_int32
1050,no,,test_ndimension_mlu_int64
1051,no,,test_ndimension_mlu_int8
1052,no,,test_ndimension_mlu_uint8
1053,no,,test_ne_equal_mlu_float16
1054,no,,test_ne_equal_mlu_float32
1055,no,,test_ne_equal_mlu_float64
1056,no,,test_ne_equal_mlu_int16
1057,no,,test_ne_equal_mlu_int32
1058,no,,test_ne_equal_mlu_int64
1059,no,,test_ne_equal_mlu_int8
1060,no,,test_ne_equal_mlu_uint8
1061,no,,test_ne_inplace_equal_mlu_float16
1062,no,,test_ne_inplace_equal_mlu_float32
1063,no,,test_ne_inplace_equal_mlu_float64
1064,no,,test_ne_inplace_equal_mlu_int16
1065,no,,test_ne_inplace_equal_mlu_int32
1066,no,,test_ne_inplace_equal_mlu_int64
1067,no,,test_ne_inplace_equal_mlu_int8
1068,no,,test_ne_inplace_equal_mlu_uint8
1069,no,,test_ne_inplace_mlu_float16
1070,no,,test_ne_inplace_mlu_float32
1071,no,,test_ne_inplace_mlu_float64
1072,no,,test_ne_inplace_mlu_int16
1073,no,,test_ne_inplace_mlu_int32
1074,no,,test_ne_inplace_mlu_int64
1075,no,,test_ne_inplace_mlu_int8
1076,no,,test_ne_inplace_mlu_uint8
1077,no,,test_ne_mlu_float16
1078,no,,test_ne_mlu_float32
1079,no,,test_ne_mlu_float64
1080,no,,test_ne_mlu_int16
1081,no,,test_ne_mlu_int32
1082,no,,test_ne_mlu_int64
1083,no,,test_ne_mlu_int8
1084,no,,test_ne_mlu_uint8
1085,yes,"[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2583][neg_][thread:140219569719040][process:16986]: OpMethods::neg_ Op running on CPU!
",test_neg_inplace_mlu_float16
1086,yes,"[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2583][neg_][thread:140219569719040][process:16986]: OpMethods::neg_ Op running on CPU!
",test_neg_inplace_mlu_float32
1087,yes,"[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2583][neg_][thread:140219569719040][process:16986]: OpMethods::neg_ Op running on CPU!
",test_neg_inplace_mlu_float64
1088,no,,test_neg_mlu_float16
1089,no,,test_neg_mlu_float32
1090,no,,test_neg_mlu_float64
1091,no,,test_nelement_mlu_float16
1092,no,,test_nelement_mlu_float32
1093,no,,test_nelement_mlu_float64
1094,no,,test_nelement_mlu_int16
1095,no,,test_nelement_mlu_int32
1096,no,,test_nelement_mlu_int64
1097,no,,test_nelement_mlu_int8
1098,no,,test_nelement_mlu_uint8
1099,no,,test_new_ones_mlu_float16
1100,no,,test_new_ones_mlu_float32
1101,no,,test_new_ones_mlu_float64
1102,no,,test_new_ones_mlu_int16
1103,no,,test_new_ones_mlu_int32
1104,no,,test_new_ones_mlu_int64
1105,no,,test_new_ones_mlu_int8
1106,no,,test_new_ones_mlu_uint8
1107,no,,test_new_zeros_mlu_float16
1108,no,,test_new_zeros_mlu_float32
1109,no,,test_new_zeros_mlu_float64
1110,no,,test_new_zeros_mlu_int16
1111,no,,test_new_zeros_mlu_int32
1112,no,,test_new_zeros_mlu_int64
1113,no,,test_new_zeros_mlu_int8
1114,no,,test_new_zeros_mlu_uint8
1115,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/nonzero.cpp][line: 16][cnnl_nonzero][thread:140219569719040][process:16986]: 
self dtype of mlu nonzero op not implemented for Half
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 831][nonzero][thread:140219569719040][process:16986]: OpMethods::nonzero Op running on CPU!
",test_nonzero_mlu_float16
1116,no,,test_nonzero_mlu_float32
1117,no,,test_nonzero_mlu_float64
1118,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/nonzero.cpp][line: 16][cnnl_nonzero][thread:140219569719040][process:16986]: 
self dtype of mlu nonzero op not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 831][nonzero][thread:140219569719040][process:16986]: OpMethods::nonzero Op running on CPU!
",test_nonzero_mlu_int16
1119,no,,test_nonzero_mlu_int32
1120,no,,test_nonzero_mlu_int64
1121,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/nonzero.cpp][line: 16][cnnl_nonzero][thread:140219569719040][process:16986]: 
self dtype of mlu nonzero op not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 831][nonzero][thread:140219569719040][process:16986]: OpMethods::nonzero Op running on CPU!
",test_nonzero_mlu_int8
1122,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/nonzero.cpp][line: 16][cnnl_nonzero][thread:140219569719040][process:16986]: 
self dtype of mlu nonzero op not implemented for Byte
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 831][nonzero][thread:140219569719040][process:16986]: OpMethods::nonzero Op running on CPU!
",test_nonzero_mlu_uint8
1123,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 24 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.6105904579162598 (3.1667532920837402 vs. 3.77734375), which occurred at index (2, 2).
",test_norm_3_norm_dim_mlu_float16
1124,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 25 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.629040002822876 (2.472525119781494 vs. 3.10156512260437), which occurred at index (1, 3).
",test_norm_3_norm_dim_mlu_float32
1125,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 25 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.7338275887369576 (2.7322626135945853 vs. 3.466090202331543), which occurred at index (1, 1).
",test_norm_3_norm_dim_mlu_float64
1126,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 5.954036235809326 (6.225651264190674 vs. 12.1796875), which occurred at index 0.
",test_norm_3_norm_mlu_float16
1127,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 5.336094856262207 (5.992339134216309 vs. 11.328433990478516), which occurred at index 0.
",test_norm_3_norm_mlu_float32
1128,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 5.436648302604328 (6.056176251839031 vs. 11.49282455444336), which occurred at index 0.
",test_norm_3_norm_mlu_float64
1129,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 24 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.6033942699432373 (3.0548088550567627 vs. 3.658203125), which occurred at index (1, 0).
",test_norm_3_norm_neg_dim_mlu_float16
1130,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 25 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.6598289012908936 (3.0356478691101074 vs. 3.695476770401001), which occurred at index (0, 4).
",test_norm_3_norm_neg_dim_mlu_float32
1131,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 25 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.5143585588073201 (2.8753003691101604 vs. 3.3896589279174805), which occurred at index (4, 1).
",test_norm_3_norm_neg_dim_mlu_float64
1132,no,,test_norm_mlu_float16
1133,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0001506805419921875 (11.240987777709961 vs. 11.241138458251953), which occurred at index 0.
",test_norm_mlu_float32
1134,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0001997264884234795 (11.311417034532857 vs. 11.311217308044434), which occurred at index 0.
",test_norm_mlu_float64
1135,no,,test_numel_mlu_float16
1136,no,,test_numel_mlu_float32
1137,no,,test_numel_mlu_float64
1138,no,,test_numel_mlu_int16
1139,no,,test_numel_mlu_int32
1140,no,,test_numel_mlu_int64
1141,no,,test_numel_mlu_int8
1142,no,,test_numel_mlu_uint8
1143,no,,test_permute_mlu_float16
1144,no,,test_permute_mlu_float32
1145,no,,test_permute_mlu_float64
1146,no,,test_permute_mlu_int16
1147,no,,test_permute_mlu_int32
1148,no,,test_permute_mlu_int64
1149,no,,test_permute_mlu_int8
1150,no,,test_permute_mlu_uint8
1151,no,,test_pow_-1_mlu_float16
1152,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.00042724609375 (-897.7310180664062 vs. -897.7305908203125), which occurred at index (0, 2, 1).
",test_pow_-1_mlu_float32
1153,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 2 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.2453022893387242e-05 (-88.71527819032758 vs. -88.71525573730469), which occurred at index (4, 2, 2).
",test_pow_-1_mlu_float64
1154,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 12 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.000732421875 (1187.01171875 vs. 1187.010986328125), which occurred at index (3, 4, 2).
",test_pow_-2_mlu_float32
1155,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 7 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.00040290152560373826 (772.2437500694944 vs. 772.2433471679688), which occurred at index (0, 3, 0).
",test_pow_-2_mlu_float64
1156,no,,test_pow_1_mlu_float16
1157,no,,test_pow_1_mlu_float32
1158,no,,test_pow_1_mlu_float64
1159,no,,test_pow_2_mlu_float16
1160,no,,test_pow_2_mlu_float32
1161,no,,test_pow_2_mlu_float64
1162,no,,test_pow_3_mlu_float16
1163,no,,test_pow_3_mlu_float32
1164,no,,test_pow_3_mlu_float64
1165,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 1 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.1217041015625 (-372.6282958984375 vs. -372.75), which occurred at index (1, 2, 0).
",test_pow_inplace_-1_mlu_float16
1166,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 105 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0149993896484375 (102.91663360595703 vs. 102.93163299560547), which occurred at index (4, 4, 3).
",test_pow_inplace_-1_mlu_float32
1167,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 3 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0003018201532540843 (469.613766175622 vs. 469.61346435546875), which occurred at index (2, 0, 2).
",test_pow_inplace_-1_mlu_float64
1168,no,,test_pow_inplace_1_mlu_float16
1169,no,,test_pow_inplace_1_mlu_float32
1170,no,,test_pow_inplace_1_mlu_float64
1171,no,,test_pow_inplace_2_mlu_float16
1172,no,,test_pow_inplace_2_mlu_float32
1173,no,,test_pow_inplace_2_mlu_float64
1174,no,,test_pow_inplace_3_mlu_float16
1175,no,,test_pow_inplace_3_mlu_float32
1176,no,,test_pow_inplace_3_mlu_float64
1177,yes,"only support interger exponent at present
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 3074][pow_][thread:140219569719040][process:16986]: OpMethods::pow_ Op running on CPU!
",test_pow_inplace_mlu_float16
1178,yes,"only support interger exponent at present
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 3074][pow_][thread:140219569719040][process:16986]: OpMethods::pow_ Op running on CPU!
",test_pow_inplace_mlu_float32
1179,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
only support interger exponent at present
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 3074][pow_][thread:140219569719040][process:16986]: OpMethods::pow_ Op running on CPU!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_pow_inplace_mlu_float64
1180,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 67 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 67 nan comparisons). The greatest difference was nan (nan vs. 4.5239925384521484e-05), which occurred at index (0, 0, 1).
",test_pow_inplace_tensor_mlu_float16
1181,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 103 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 55 nan comparisons). The greatest difference was nan (nan vs. 3.0590231858695915e-07), which occurred at index (0, 0, 3).
",test_pow_inplace_tensor_mlu_float32
1182,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 116 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 65 nan comparisons). The greatest difference was nan (nan vs. 0.00013528105046134442), which occurred at index (0, 0, 0).
",test_pow_inplace_tensor_mlu_float64
1183,yes,"only support interger exponent at present
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 3032][pow][thread:140219569719040][process:16986]: OpMethods::pow Op running on CPU!
",test_pow_mlu_float16
1184,yes,"only support interger exponent at present
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 3032][pow][thread:140219569719040][process:16986]: OpMethods::pow Op running on CPU!
",test_pow_mlu_float32
1185,yes,"<class 'RuntimeError'> : copy tensor from cpu to mlu:0 failed!
only support interger exponent at present
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 3032][pow][thread:140219569719040][process:16986]: OpMethods::pow Op running on CPU!
cnnlMalloc datacast fail! expected smaller than 3.40282e+38 and greater than -3.40282e+38but got nan
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 90][copy_][thread:140219569719040][process:16986]: OpMethods::copy_ Op running on CPU!
",test_pow_mlu_float64
1186,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 62 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 62 nan comparisons). The greatest difference was nan (nan vs. 0.0020694732666015625), which occurred at index (0, 0, 3).
",test_pow_tensor_mlu_float16
1187,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 106 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 58 nan comparisons). The greatest difference was nan (nan vs. 5.3361509344540536e-05), which occurred at index (0, 0, 0).
",test_pow_tensor_mlu_float32
1188,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 114 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 69 nan comparisons). The greatest difference was nan (nan vs. 0.0008073239005170763), which occurred at index (0, 0, 1).
",test_pow_tensor_mlu_float64
1189,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 1 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0012063980102539062 (-1.530503273010254 vs. -1.529296875), which occurred at index (0, 2).
",test_prod_dim_mlu_float16
1190,no,,test_prod_dim_mlu_float32
1191,no,,test_prod_dim_mlu_float64
1192,no,,test_prod_dim_mlu_int16
1193,no,,test_prod_dim_mlu_int32
1194,no,,test_prod_dim_mlu_int64
1195,no,,test_prod_dim_mlu_int8
1196,no,,test_prod_dim_mlu_uint8
1197,no,,test_prod_mlu_float16
1198,no,,test_prod_mlu_float32
1199,no,,test_prod_mlu_float64
1200,no,,test_prod_mlu_int16
1201,no,,test_prod_mlu_int32
1202,no,,test_prod_mlu_int64
1203,no,,test_prod_mlu_int8
1204,no,,test_prod_mlu_uint8
1205,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 1 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0063323974609375 (20.709457397460938 vs. 20.703125), which occurred at index (2, 3).
",test_prod_neg_dim_mlu_float16
1206,no,,test_prod_neg_dim_mlu_float32
1207,no,,test_prod_neg_dim_mlu_float64
1208,no,,test_prod_neg_dim_mlu_int16
1209,no,,test_prod_neg_dim_mlu_int32
1210,no,,test_prod_neg_dim_mlu_int64
1211,no,,test_prod_neg_dim_mlu_int8
1212,no,,test_prod_neg_dim_mlu_uint8
1213,yes,"<class 'RuntimeError'> : _th_put_ not supported on CPUType for Half
",test_put__accumulate_mlu_float16
1214,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_float32
1215,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_float64
1216,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_int16
1217,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_int32
1218,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_int64
1219,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_int8
1220,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__accumulate_mlu_uint8
1221,yes,"<class 'RuntimeError'> : _th_put_ not supported on CPUType for Half
",test_put__empty_mlu_float16
1222,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_float32
1223,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_float64
1224,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_int16
1225,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_int32
1226,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_int64
1227,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_int8
1228,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__empty_mlu_uint8
1229,yes,"<class 'RuntimeError'> : _th_put_ not supported on CPUType for Half
",test_put__mlu_float16
1230,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_float32
1231,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_float64
1232,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_int16
1233,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_int32
1234,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_int64
1235,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_int8
1236,yes,"<class 'RuntimeError'> : Could not run 'aten::put_' with arguments from the 'MLU' backend. 'aten::put_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_put__mlu_uint8
1237,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_big_mlu_float32
1238,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_big_mlu_float64
1239,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_fat_mlu_float32
1240,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_fat_mlu_float64
1241,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_skinny_mlu_float32
1242,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_skinny_mlu_float64
1243,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_square_mlu_float32
1244,yes,"<class 'RuntimeError'> : Could not run 'aten::_qr_helper' with arguments from the 'MLU' backend. 'aten::_qr_helper' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_qr_square_mlu_float64
1245,no,,test_rad2deg_inplace_mlu_float16
1246,no,,test_rad2deg_inplace_mlu_float32
1247,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 2 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.3148400114459946e-05 (-128.85080167093582 vs. -128.85081481933594), which occurred at index (4, 0, 0).
",test_rad2deg_inplace_mlu_float64
1248,no,,test_rad2deg_mlu_float16
1249,no,,test_rad2deg_mlu_float32
1250,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 2 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.168944828577878e-05 (-143.7795751025439 vs. -143.7795867919922), which occurred at index (3, 1, 4).
",test_rad2deg_mlu_float64
1251,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 1 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.2716064453125 (1423.7283935546875 vs. 1424.0), which occurred at index (1, 4, 3).
",test_reciprocal_inplace_mlu_float16
1252,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 54 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.06451416015625 (912.064208984375 vs. 911.9996948242188), which occurred at index (0, 4, 0).
",test_reciprocal_inplace_mlu_float32
1253,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 47 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.004841421151091652 (-63.92773876001828 vs. -63.92289733886719), which occurred at index (2, 4, 0).
",test_reciprocal_inplace_mlu_float64
1254,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.1, found 1 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.18328857421875 (-662.8167114257812 vs. -663.0), which occurred at index (4, 3, 2).
",test_reciprocal_mlu_float16
1255,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 54 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0009441375732421875 (12.488509178161621 vs. 12.487565040588379), which occurred at index (3, 4, 4).
",test_reciprocal_mlu_float32
1256,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 54 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.021405564790967446 (-158.64125312661528 vs. -158.66265869140625), which occurred at index (1, 1, 4).
",test_reciprocal_mlu_float64
1257,no,,test_remainder_inplace_negative_tensor_mlu_float16
1258,no,,test_remainder_inplace_negative_tensor_mlu_float32
1259,no,,test_remainder_inplace_negative_tensor_mlu_float64
1260,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4208][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_negative_tensor_mlu_int16
1261,no,,test_remainder_inplace_negative_tensor_mlu_int32
1262,no,,test_remainder_inplace_negative_tensor_mlu_int64
1263,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4208][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_negative_tensor_mlu_int8
1264,no,,test_remainder_inplace_negative_value_mlu_float16
1265,no,,test_remainder_inplace_negative_value_mlu_float32
1266,no,,test_remainder_inplace_negative_value_mlu_float64
1267,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4199][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_negative_value_mlu_int16
1268,no,,test_remainder_inplace_negative_value_mlu_int32
1269,no,,test_remainder_inplace_negative_value_mlu_int64
1270,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4199][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_negative_value_mlu_int8
1271,no,,test_remainder_inplace_tensor_mlu_float16
1272,no,,test_remainder_inplace_tensor_mlu_float32
1273,no,,test_remainder_inplace_tensor_mlu_float64
1274,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4208][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_tensor_mlu_int16
1275,no,,test_remainder_inplace_tensor_mlu_int32
1276,no,,test_remainder_inplace_tensor_mlu_int64
1277,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4208][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_tensor_mlu_int8
1278,no,,test_remainder_inplace_value_mlu_float16
1279,no,,test_remainder_inplace_value_mlu_float32
1280,no,,test_remainder_inplace_value_mlu_float64
1281,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4199][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_value_mlu_int16
1282,no,,test_remainder_inplace_value_mlu_int32
1283,no,,test_remainder_inplace_value_mlu_int64
1284,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4199][remainder_][thread:140219569719040][process:16986]: OpMethods::remainder_ Op running on CPU!
",test_remainder_inplace_value_mlu_int8
1285,no,,test_remainder_negative_tensor_mlu_float16
1286,no,,test_remainder_negative_tensor_mlu_float32
1287,no,,test_remainder_negative_tensor_mlu_float64
1288,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4191][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_negative_tensor_mlu_int16
1289,no,,test_remainder_negative_tensor_mlu_int32
1290,no,,test_remainder_negative_tensor_mlu_int64
1291,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4191][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_negative_tensor_mlu_int8
1292,no,,test_remainder_negative_value_mlu_float16
1293,no,,test_remainder_negative_value_mlu_float32
1294,no,,test_remainder_negative_value_mlu_float64
1295,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4184][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_negative_value_mlu_int16
1296,no,,test_remainder_negative_value_mlu_int32
1297,no,,test_remainder_negative_value_mlu_int64
1298,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4184][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_negative_value_mlu_int8
1299,no,,test_remainder_tensor_mlu_float16
1300,no,,test_remainder_tensor_mlu_float32
1301,no,,test_remainder_tensor_mlu_float64
1302,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4191][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_tensor_mlu_int16
1303,no,,test_remainder_tensor_mlu_int32
1304,no,,test_remainder_tensor_mlu_int64
1305,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4191][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_tensor_mlu_int8
1306,no,,test_remainder_value_mlu_float16
1307,no,,test_remainder_value_mlu_float32
1308,no,,test_remainder_value_mlu_float64
1309,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4184][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_value_mlu_int16
1310,no,,test_remainder_value_mlu_int32
1311,no,,test_remainder_value_mlu_int64
1312,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/remainder_internal.cpp][line: 20][cnnl_remainder_internal][thread:140219569719040][process:16986]: 
cnnl_remainder is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 4184][remainder][thread:140219569719040][process:16986]: OpMethods::remainder Op running on CPU!
",test_remainder_value_mlu_int8
1313,yes,"<class 'RuntimeError'> : _th_renorm not supported on CPUType for Half
",test_renorm_1_5_norm_mlu_float16
1314,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm' with arguments from the 'MLU' backend. 'aten::renorm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_renorm_1_5_norm_mlu_float32
1315,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm' with arguments from the 'MLU' backend. 'aten::renorm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_renorm_1_5_norm_mlu_float64
1316,yes,"<class 'RuntimeError'> : _th_renorm not supported on CPUType for Half
",test_renorm_2_norm_mlu_float16
1317,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm' with arguments from the 'MLU' backend. 'aten::renorm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_renorm_2_norm_mlu_float32
1318,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm' with arguments from the 'MLU' backend. 'aten::renorm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_renorm_2_norm_mlu_float64
1319,yes,"<class 'RuntimeError'> : _th_renorm not supported on CPUType for Half
",test_renorm_2_norm_neg_dim_mlu_float16
1320,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm' with arguments from the 'MLU' backend. 'aten::renorm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_renorm_2_norm_neg_dim_mlu_float32
1321,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm' with arguments from the 'MLU' backend. 'aten::renorm' is only available for these backends: [CPU, Autograd, Profiler, Tracer, Autocast].
",test_renorm_2_norm_neg_dim_mlu_float64
1322,yes,"<class 'RuntimeError'> : _th_renorm_ not supported on CPUType for Half
",test_renorm_inplace_1_5_norm_mlu_float16
1323,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm_' with arguments from the 'MLU' backend. 'aten::renorm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_renorm_inplace_1_5_norm_mlu_float32
1324,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm_' with arguments from the 'MLU' backend. 'aten::renorm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_renorm_inplace_1_5_norm_mlu_float64
1325,yes,"<class 'RuntimeError'> : _th_renorm_ not supported on CPUType for Half
",test_renorm_inplace_2_norm_mlu_float16
1326,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm_' with arguments from the 'MLU' backend. 'aten::renorm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_renorm_inplace_2_norm_mlu_float32
1327,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm_' with arguments from the 'MLU' backend. 'aten::renorm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_renorm_inplace_2_norm_mlu_float64
1328,yes,"<class 'RuntimeError'> : _th_renorm_ not supported on CPUType for Half
",test_renorm_inplace_2_norm_neg_dim_mlu_float16
1329,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm_' with arguments from the 'MLU' backend. 'aten::renorm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_renorm_inplace_2_norm_neg_dim_mlu_float32
1330,yes,"<class 'RuntimeError'> : Could not run 'aten::renorm_' with arguments from the 'MLU' backend. 'aten::renorm_' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_renorm_inplace_2_norm_neg_dim_mlu_float64
1331,no,,test_repeat_mlu_float16
1332,no,,test_repeat_mlu_float32
1333,no,,test_repeat_mlu_float64
1334,no,,test_repeat_mlu_int16
1335,no,,test_repeat_mlu_int32
1336,no,,test_repeat_mlu_int64
1337,no,,test_repeat_mlu_int8
1338,no,,test_repeat_mlu_uint8
1339,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_default_mlu_complex128
1340,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_default_mlu_complex64
1341,yes,"<class 'RuntimeError'> : ""flip_cpu"" not implemented for 'Half'
",test_rot90_default_mlu_float16
1342,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 125 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 3 nan comparisons). The greatest difference was nan (-0.10318538546562195 vs. nan), which occurred at index (0, 2, 3).
",test_rot90_default_mlu_float32
1343,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 100 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.1337947857476824 (-2.162739099273836 vs. 0.9710556864738464), which occurred at index (1, 3, 2).
",test_rot90_default_mlu_float64
1344,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 117 different element(s) (out of 125), with the greatest difference of 32639 (-5 vs. 32634) occuring at index (0, 0, 2).
",test_rot90_default_mlu_int16
1345,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 117 different element(s) (out of 125), with the greatest difference of 925353392 (-4 vs. 925353388) occuring at index (3, 3, 2).
",test_rot90_default_mlu_int32
1346,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 85 different element(s) (out of 125), with the greatest difference of 140165663326251 (-3 vs. 140165663326248) occuring at index (0, 0, 0).
",test_rot90_default_mlu_int64
1347,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 114 different element(s) (out of 125), with the greatest difference of 114 (-5 vs. 109) occuring at index (2, 4, 3).
",test_rot90_default_mlu_int8
1348,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 114 different element(s) (out of 125), with the greatest difference of 174 (2 vs. 176) occuring at index (2, 2, 4).
",test_rot90_default_mlu_uint8
1349,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_k1_d01_mlu_complex128
1350,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_k1_d01_mlu_complex64
1351,yes,"<class 'RuntimeError'> : ""flip_cpu"" not implemented for 'Half'
",test_rot90_k1_d01_mlu_float16
1352,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 25 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.793621778488159 (-2.793621778488159 vs. 3.41340141427272e-35), which occurred at index (1, 3).
",test_rot90_k1_d01_mlu_float32
1353,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 25 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.820217657801892 (-2.820217657801892 vs. 0.0), which occurred at index (1, 0).
",test_rot90_k1_d01_mlu_float64
1354,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 24 different element(s) (out of 25), with the greatest difference of 32260 (4 vs. 32264) occuring at index (4, 4).
",test_rot90_k1_d01_mlu_int16
1355,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 23 different element(s) (out of 25), with the greatest difference of 594379644 (4 vs. -594379640) occuring at index (0, 0).
",test_rot90_k1_d01_mlu_int32
1356,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 22 different element(s) (out of 25), with the greatest difference of 140165663325469 (-5 vs. 140165663325464) occuring at index (0, 0).
",test_rot90_k1_d01_mlu_int64
1357,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 25 different element(s) (out of 25), with the greatest difference of 131 (-4 vs. 127) occuring at index (0, 1).
",test_rot90_k1_d01_mlu_int8
1358,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 24 different element(s) (out of 25), with the greatest difference of 220 (0 vs. 220) occuring at index (1, 2).
",test_rot90_k1_d01_mlu_uint8
1359,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_k1_d12_mlu_complex128
1360,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_k1_d12_mlu_complex64
1361,yes,"<class 'RuntimeError'> : ""flip_cpu"" not implemented for 'Half'
",test_rot90_k1_d12_mlu_float16
1362,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 125 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 2 nan comparisons). The greatest difference was nan (-0.3359907865524292 vs. nan), which occurred at index (4, 2, 2).
",test_rot90_k1_d12_mlu_float32
1363,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 101 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 4.436991855365349 (-2.847716137630058 vs. 1.5892757177352905), which occurred at index (2, 0, 0).
",test_rot90_k1_d12_mlu_float64
1364,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 99 different element(s) (out of 125), with the greatest difference of 32632 (2 vs. 32634) occuring at index (0, 2, 0).
",test_rot90_k1_d12_mlu_int16
1365,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 125 different element(s) (out of 125), with the greatest difference of 1139441659 (-5 vs. -1139441664) occuring at index (1, 2, 2).
",test_rot90_k1_d12_mlu_int32
1366,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 87 different element(s) (out of 125), with the greatest difference of 140165663326566 (2 vs. 140165663326568) occuring at index (0, 0, 0).
",test_rot90_k1_d12_mlu_int64
1367,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 115 different element(s) (out of 125), with the greatest difference of 131 (-4 vs. 127) occuring at index (0, 0, 1).
",test_rot90_k1_d12_mlu_int8
1368,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 111 different element(s) (out of 125), with the greatest difference of 246 (2 vs. 248) occuring at index (4, 4, 0).
",test_rot90_k1_d12_mlu_uint8
1369,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_k1_neg_d_mlu_complex128
1370,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_rot90_k1_neg_d_mlu_complex64
1371,yes,"<class 'RuntimeError'> : ""flip_cpu"" not implemented for 'Half'
",test_rot90_k1_neg_d_mlu_float16
1372,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 125 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.5845632502852868e+29 (0.348243772983551 vs. 1.5845632502852868e+29), which occurred at index (0, 1, 3).
",test_rot90_k1_neg_d_mlu_float32
1373,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 101 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.6110846610331184 (1.528789481666053 vs. -1.0822951793670654), which occurred at index (2, 3, 4).
",test_rot90_k1_neg_d_mlu_float64
1374,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 91 different element(s) (out of 125), with the greatest difference of 32638 (-4 vs. 32634) occuring at index (0, 2, 0).
",test_rot90_k1_neg_d_mlu_int16
1375,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 125 different element(s) (out of 125), with the greatest difference of 1117945859 (3 vs. -1117945856) occuring at index (4, 3, 2).
",test_rot90_k1_neg_d_mlu_int32
1376,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 83 different element(s) (out of 125), with the greatest difference of 140165663326037 (3 vs. 140165663326040) occuring at index (0, 1, 0).
",test_rot90_k1_neg_d_mlu_int64
1377,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 114 different element(s) (out of 125), with the greatest difference of 127 (-2 vs. 125) occuring at index (4, 0, 4).
",test_rot90_k1_neg_d_mlu_int8
1378,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 117 different element(s) (out of 125), with the greatest difference of 255 (0 vs. 255) occuring at index (1, 2, 4).
",test_rot90_k1_neg_d_mlu_uint8
1379,no,,test_round_inplace_mlu_float16
1380,no,,test_round_inplace_mlu_float32
1381,no,,test_round_inplace_mlu_float64
1382,no,,test_round_mlu_float16
1383,no,,test_round_mlu_float32
1384,no,,test_round_mlu_float64
1385,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.0001, found 20 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 20 nan comparisons). The greatest difference was nan (nan vs. 3.4028234663852886e+38), which occurred at index (0, 1, 2).
",test_rsqrt_inplace_mlu_float32
1386,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.0001, found 14 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 14 nan comparisons). The greatest difference was nan (nan vs. 3.4028234663852886e+38), which occurred at index (0, 3, 2).
",test_rsqrt_inplace_mlu_float64
1387,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.0001, found 17 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 15 nan comparisons). The greatest difference was nan (nan vs. 3.4028234663852886e+38), which occurred at index (0, 0, 0).
",test_rsqrt_mlu_float32
1388,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.0001, found 12 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 12 nan comparisons). The greatest difference was nan (nan vs. 3.4028234663852886e+38), which occurred at index (0, 2, 0).
",test_rsqrt_mlu_float64
1389,no,,test_sigmoid_inplace_mlu_float16
1390,no,,test_sigmoid_inplace_mlu_float32
1391,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/activation_internal.cpp][line: 23][cnnl_activation_internal][thread:140219569719040][process:16986]: 
input must be float/half
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2368][sigmoid_][thread:140219569719040][process:16986]: OpMethods::sigmoid_ Op running on CPU!
",test_sigmoid_inplace_mlu_float64
1392,no,,test_sigmoid_mlu_float16
1393,no,,test_sigmoid_mlu_float32
1394,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/activation_internal.cpp][line: 23][cnnl_activation_internal][thread:140219569719040][process:16986]: 
input must be float/half
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 2362][sigmoid][thread:140219569719040][process:16986]: OpMethods::sigmoid Op running on CPU!
",test_sigmoid_mlu_float64
1395,no,,test_sign_inplace_mlu_float16
1396,no,,test_sign_inplace_mlu_float32
1397,no,,test_sign_inplace_mlu_float64
1398,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 111 different element(s) (out of 125), with the greatest difference of 15359 (1 vs. 15360) occuring at index (4, 4, 3).
",test_sign_inplace_mlu_int16
1399,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 94 different element(s) (out of 125), with the greatest difference of 15359 (1 vs. 15360) occuring at index (2, 4, 1).
",test_sign_inplace_mlu_int32
1400,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 90 different element(s) (out of 125), with the greatest difference of 15359 (1 vs. 15360) occuring at index (2, 4, 0).
",test_sign_inplace_mlu_int64
1401,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 118 different element(s) (out of 125), with the greatest difference of 67 (-1 vs. -68) occuring at index (4, 4, 3).
",test_sign_inplace_mlu_int8
1402,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 113 different element(s) (out of 125), with the greatest difference of 60 (0 vs. 60) occuring at index (3, 0, 2).
",test_sign_inplace_mlu_uint8
1403,no,,test_sign_mlu_float16
1404,no,,test_sign_mlu_float32
1405,no,,test_sign_mlu_float64
1406,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 110 different element(s) (out of 125), with the greatest difference of 15359 (1 vs. 15360) occuring at index (4, 4, 1).
",test_sign_mlu_int16
1407,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 109 different element(s) (out of 125), with the greatest difference of 65535 (-1 vs. -65536) occuring at index (2, 2, 2).
",test_sign_mlu_int32
1408,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 108 different element(s) (out of 125), with the greatest difference of 65535 (-1 vs. -65536) occuring at index (2, 2, 2).
",test_sign_mlu_int64
1409,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 118 different element(s) (out of 125), with the greatest difference of 67 (-1 vs. -68) occuring at index (4, 3, 2).
",test_sign_mlu_int8
1410,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 114 different element(s) (out of 125), with the greatest difference of 60 (0 vs. 60) occuring at index (4, 1, 0).
",test_sign_mlu_uint8
1411,no,,test_sin_inplace_mlu_float16
1412,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 13 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 8.314847946166992e-05 (-0.9898797273635864 vs. -0.9897965788841248), which occurred at index (3, 0, 0).
",test_sin_inplace_mlu_float32
1413,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 11 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 7.449816033638923e-05 (-0.2152994347648362 vs. -0.21522493660449982), which occurred at index (2, 2, 1).
",test_sin_inplace_mlu_float64
1414,no,,test_sin_mlu_float16
1415,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 18 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 9.78708267211914e-05 (-0.9397369623184204 vs. -0.9396390914916992), which occurred at index (0, 3, 2).
",test_sin_mlu_float32
1416,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 16 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 8.525990491470292e-05 (-0.9422665491009291 vs. -0.9421812891960144), which occurred at index (1, 0, 4).
",test_sin_mlu_float64
1417,yes,"<class 'RuntimeError'> : ""sinh_cpu"" not implemented for 'Half'
",test_sinh_inplace_mlu_float16
1418,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_sinh_inplace_mlu_float32
1419,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_sinh_inplace_mlu_float64
1420,yes,"<class 'RuntimeError'> : ""sinh_cpu"" not implemented for 'Half'
",test_sinh_mlu_float16
1421,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_sinh_mlu_float32
1422,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_sinh_mlu_float64
1423,no,,test_size_dim_mlu_float16
1424,no,,test_size_dim_mlu_float32
1425,no,,test_size_dim_mlu_float64
1426,no,,test_size_dim_mlu_int16
1427,no,,test_size_dim_mlu_int32
1428,no,,test_size_dim_mlu_int64
1429,no,,test_size_dim_mlu_int8
1430,no,,test_size_dim_mlu_uint8
1431,no,,test_size_mlu_float16
1432,no,,test_size_mlu_float32
1433,no,,test_size_mlu_float64
1434,no,,test_size_mlu_int16
1435,no,,test_size_mlu_int32
1436,no,,test_size_mlu_int64
1437,no,,test_size_mlu_int8
1438,no,,test_size_mlu_uint8
1439,no,,test_size_neg_dim_mlu_float16
1440,no,,test_size_neg_dim_mlu_float32
1441,no,,test_size_neg_dim_mlu_float64
1442,no,,test_size_neg_dim_mlu_int16
1443,no,,test_size_neg_dim_mlu_int32
1444,no,,test_size_neg_dim_mlu_int64
1445,no,,test_size_neg_dim_mlu_int8
1446,no,,test_size_neg_dim_mlu_uint8
1447,no,,test_sort_dim_descending_mlu_float16
1448,no,,test_sort_dim_descending_mlu_float32
1449,no,,test_sort_dim_descending_mlu_float64
1450,no,,test_sort_dim_descending_mlu_int16
1451,no,,test_sort_dim_descending_mlu_int32
1452,no,,test_sort_dim_descending_mlu_int64
1453,no,,test_sort_dim_descending_mlu_int8
1454,yes,"[2021-7-16 17:36:54] [CNNL] [Error]: [cnnlTopKTensor] The data type of input should be float or half. But now input_desc->dtype is CNNL_DTYPE_INVALID.
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/topk_internal.cpp][line: 94][cnnl_sort_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1827][sort][thread:140219569719040][process:16986]: OpMethods::sort Op running on CPU!
",test_sort_dim_descending_mlu_uint8
1455,no,,test_sort_dim_mlu_float16
1456,no,,test_sort_dim_mlu_float32
1457,no,,test_sort_dim_mlu_float64
1458,no,,test_sort_dim_mlu_int16
1459,no,,test_sort_dim_mlu_int32
1460,no,,test_sort_dim_mlu_int64
1461,no,,test_sort_dim_mlu_int8
1462,yes,"[2021-7-16 17:36:54] [CNNL] [Error]: [cnnlTopKTensor] The data type of input should be float or half. But now input_desc->dtype is CNNL_DTYPE_INVALID.
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/topk_internal.cpp][line: 94][cnnl_sort_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1827][sort][thread:140219569719040][process:16986]: OpMethods::sort Op running on CPU!
",test_sort_dim_mlu_uint8
1463,no,,test_sort_mlu_float16
1464,no,,test_sort_mlu_float32
1465,no,,test_sort_mlu_float64
1466,no,,test_sort_mlu_int16
1467,no,,test_sort_mlu_int32
1468,no,,test_sort_mlu_int64
1469,no,,test_sort_mlu_int8
1470,yes,"[2021-7-16 17:36:54] [CNNL] [Error]: [cnnlTopKTensor] The data type of input should be float or half. But now input_desc->dtype is CNNL_DTYPE_INVALID.
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/topk_internal.cpp][line: 94][cnnl_sort_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1827][sort][thread:140219569719040][process:16986]: OpMethods::sort Op running on CPU!
",test_sort_mlu_uint8
1471,no,,test_sort_neg_dim_descending_mlu_float16
1472,no,,test_sort_neg_dim_descending_mlu_float32
1473,no,,test_sort_neg_dim_descending_mlu_float64
1474,no,,test_sort_neg_dim_descending_mlu_int16
1475,no,,test_sort_neg_dim_descending_mlu_int32
1476,no,,test_sort_neg_dim_descending_mlu_int64
1477,no,,test_sort_neg_dim_descending_mlu_int8
1478,yes,"[2021-7-16 17:36:54] [CNNL] [Error]: [cnnlTopKTensor] The data type of input should be float or half. But now input_desc->dtype is CNNL_DTYPE_INVALID.
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/topk_internal.cpp][line: 94][cnnl_sort_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1827][sort][thread:140219569719040][process:16986]: OpMethods::sort Op running on CPU!
",test_sort_neg_dim_descending_mlu_uint8
1479,no,,test_sort_neg_dim_mlu_float16
1480,no,,test_sort_neg_dim_mlu_float32
1481,no,,test_sort_neg_dim_mlu_float64
1482,no,,test_sort_neg_dim_mlu_int16
1483,no,,test_sort_neg_dim_mlu_int32
1484,no,,test_sort_neg_dim_mlu_int64
1485,no,,test_sort_neg_dim_mlu_int8
1486,yes,"[2021-7-16 17:36:54] [CNNL] [Error]: [cnnlTopKTensor] The data type of input should be float or half. But now input_desc->dtype is CNNL_DTYPE_INVALID.
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/topk_internal.cpp][line: 94][cnnl_sort_internal][thread:140219569719040][process:16986]: 
CNNL error: CNNL_STATUS_BAD_PARAM
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1827][sort][thread:140219569719040][process:16986]: OpMethods::sort Op running on CPU!
",test_sort_neg_dim_mlu_uint8
1487,no,,test_split_dim_mlu_float16
1488,no,,test_split_dim_mlu_float32
1489,no,,test_split_dim_mlu_float64
1490,no,,test_split_dim_mlu_int16
1491,no,,test_split_dim_mlu_int32
1492,no,,test_split_dim_mlu_int64
1493,no,,test_split_dim_mlu_int8
1494,no,,test_split_dim_mlu_uint8
1495,no,,test_split_mlu_float16
1496,no,,test_split_mlu_float32
1497,no,,test_split_mlu_float64
1498,no,,test_split_mlu_int16
1499,no,,test_split_mlu_int32
1500,no,,test_split_mlu_int64
1501,no,,test_split_mlu_int8
1502,no,,test_split_mlu_uint8
1503,no,,test_split_neg_dim_mlu_float16
1504,no,,test_split_neg_dim_mlu_float32
1505,no,,test_split_neg_dim_mlu_float64
1506,no,,test_split_neg_dim_mlu_int16
1507,no,,test_split_neg_dim_mlu_int32
1508,no,,test_split_neg_dim_mlu_int64
1509,no,,test_split_neg_dim_mlu_int8
1510,no,,test_split_neg_dim_mlu_uint8
1511,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 67 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 67 nan comparisons). The greatest difference was nan (nan vs. 6.556510925292969e-07), which occurred at index (0, 0, 2).
",test_sqrt_inplace_mlu_float16
1512,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 60 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 55 nan comparisons). The greatest difference was nan (nan vs. 6.663383373961551e-07), which occurred at index (0, 0, 0).
",test_sqrt_inplace_mlu_float32
1513,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 69 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 64 nan comparisons). The greatest difference was nan (nan vs. 6.663383373961551e-07), which occurred at index (0, 0, 0).
",test_sqrt_inplace_mlu_float64
1514,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 60 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 60 nan comparisons). The greatest difference was nan (nan vs. 6.556510925292969e-07), which occurred at index (0, 0, 3).
",test_sqrt_mlu_float16
1515,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 68 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 64 nan comparisons). The greatest difference was nan (nan vs. 6.663383373961551e-07), which occurred at index (0, 0, 1).
",test_sqrt_mlu_float32
1516,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 68 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 62 nan comparisons). The greatest difference was nan (nan vs. 6.663383373961551e-07), which occurred at index (0, 0, 0).
",test_sqrt_mlu_float64
1517,no,,test_squeeze_dim_mlu_float16
1518,no,,test_squeeze_dim_mlu_float32
1519,no,,test_squeeze_dim_mlu_float64
1520,no,,test_squeeze_dim_mlu_int16
1521,no,,test_squeeze_dim_mlu_int32
1522,no,,test_squeeze_dim_mlu_int64
1523,no,,test_squeeze_dim_mlu_int8
1524,no,,test_squeeze_dim_mlu_uint8
1525,no,,test_squeeze_inplace_dim_mlu_float16
1526,no,,test_squeeze_inplace_dim_mlu_float32
1527,no,,test_squeeze_inplace_dim_mlu_float64
1528,no,,test_squeeze_inplace_dim_mlu_int16
1529,no,,test_squeeze_inplace_dim_mlu_int32
1530,no,,test_squeeze_inplace_dim_mlu_int64
1531,no,,test_squeeze_inplace_dim_mlu_int8
1532,no,,test_squeeze_inplace_dim_mlu_uint8
1533,no,,test_squeeze_inplace_mlu_float16
1534,no,,test_squeeze_inplace_mlu_float32
1535,no,,test_squeeze_inplace_mlu_float64
1536,no,,test_squeeze_inplace_mlu_int16
1537,no,,test_squeeze_inplace_mlu_int32
1538,no,,test_squeeze_inplace_mlu_int64
1539,no,,test_squeeze_inplace_mlu_int8
1540,no,,test_squeeze_inplace_mlu_uint8
1541,no,,test_squeeze_inplace_neg_dim_mlu_float16
1542,no,,test_squeeze_inplace_neg_dim_mlu_float32
1543,no,,test_squeeze_inplace_neg_dim_mlu_float64
1544,no,,test_squeeze_inplace_neg_dim_mlu_int16
1545,no,,test_squeeze_inplace_neg_dim_mlu_int32
1546,no,,test_squeeze_inplace_neg_dim_mlu_int64
1547,no,,test_squeeze_inplace_neg_dim_mlu_int8
1548,no,,test_squeeze_inplace_neg_dim_mlu_uint8
1549,no,,test_squeeze_mlu_float16
1550,no,,test_squeeze_mlu_float32
1551,no,,test_squeeze_mlu_float64
1552,no,,test_squeeze_mlu_int16
1553,no,,test_squeeze_mlu_int32
1554,no,,test_squeeze_mlu_int64
1555,no,,test_squeeze_mlu_int8
1556,no,,test_squeeze_mlu_uint8
1557,no,,test_squeeze_neg_dim_mlu_float16
1558,no,,test_squeeze_neg_dim_mlu_float32
1559,no,,test_squeeze_neg_dim_mlu_float64
1560,no,,test_squeeze_neg_dim_mlu_int16
1561,no,,test_squeeze_neg_dim_mlu_int32
1562,no,,test_squeeze_neg_dim_mlu_int64
1563,no,,test_squeeze_neg_dim_mlu_int8
1564,no,,test_squeeze_neg_dim_mlu_uint8
1565,no,,test_std_dim_mlu_float16
1566,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 8 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 6.508827209472656e-05 (1.4123347997665405 vs. 1.4122697114944458), which occurred at index (4, 3).
",test_std_dim_mlu_float32
1567,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 4 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 7.50726615355024e-05 (1.559782772644861 vs. 1.5598578453063965), which occurred at index (0, 0).
",test_std_dim_mlu_float64
1568,no,,test_std_mlu_float16
1569,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.0251998901367188e-05 (1.0365232229232788 vs. 1.0365129709243774), which occurred at index 0.
",test_std_mlu_float32
1570,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 1 element(s) (out of 1) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.5443059064645936e-05 (1.0137208049572928 vs. 1.0137362480163574), which occurred at index 0.
",test_std_mlu_float64
1571,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=0.001, found 3 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.0012542009353637695 (1.0022307634353638 vs. 1.0009765625), which occurred at index (3, 3).
",test_std_neg_dim_mlu_float16
1572,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 4 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.325939178466797e-05 (1.7662016153335571 vs. 1.7661683559417725), which occurred at index (4, 3).
",test_std_neg_dim_mlu_float32
1573,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 3 element(s) (out of 25) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 8.772478777285819e-05 (1.4774029387406695 vs. 1.4774906635284424), which occurred at index (0, 1).
",test_std_neg_dim_mlu_float64
1574,no,,test_sub_inplace_mlu_float16
1575,no,,test_sub_inplace_mlu_float32
1576,no,,test_sub_inplace_mlu_float64
1577,no,,test_sub_inplace_mlu_int16
1578,no,,test_sub_inplace_mlu_int32
1579,no,,test_sub_inplace_mlu_int64
1580,no,,test_sub_inplace_mlu_int8
1581,no,,test_sub_inplace_mlu_uint8
1582,no,,test_sub_inplace_tensor_mlu_float16
1583,no,,test_sub_inplace_tensor_mlu_float32
1584,no,,test_sub_inplace_tensor_mlu_float64
1585,no,,test_sub_inplace_tensor_mlu_int16
1586,no,,test_sub_inplace_tensor_mlu_int32
1587,no,,test_sub_inplace_tensor_mlu_int64
1588,no,,test_sub_inplace_tensor_mlu_int8
1589,no,,test_sub_inplace_tensor_mlu_uint8
1590,no,,test_sub_mlu_float16
1591,no,,test_sub_mlu_float32
1592,no,,test_sub_mlu_float64
1593,no,,test_sub_mlu_int16
1594,no,,test_sub_mlu_int32
1595,no,,test_sub_mlu_int64
1596,no,,test_sub_mlu_int8
1597,no,,test_sub_mlu_uint8
1598,no,,test_sub_tensor_mlu_float16
1599,no,,test_sub_tensor_mlu_float32
1600,no,,test_sub_tensor_mlu_float64
1601,no,,test_sub_tensor_mlu_int16
1602,no,,test_sub_tensor_mlu_int32
1603,no,,test_sub_tensor_mlu_int64
1604,no,,test_sub_tensor_mlu_int8
1605,no,,test_sub_tensor_mlu_uint8
1606,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_sum_complex_dim_mlu_complex128
1607,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_sum_complex_dim_mlu_complex64
1608,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_sum_complex_mlu_complex128
1609,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_sum_complex_mlu_complex64
1610,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_sum_complex_neg_dim_mlu_complex128
1611,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_sum_complex_neg_dim_mlu_complex64
1612,no,,test_sum_dim_mlu_float16
1613,no,,test_sum_dim_mlu_float32
1614,no,,test_sum_dim_mlu_float64
1615,no,,test_sum_dim_mlu_int16
1616,no,,test_sum_dim_mlu_int32
1617,no,,test_sum_dim_mlu_int64
1618,no,,test_sum_dim_mlu_int8
1619,no,,test_sum_dim_mlu_uint8
1620,no,,test_sum_mlu_float16
1621,no,,test_sum_mlu_float32
1622,no,,test_sum_mlu_float64
1623,no,,test_sum_mlu_int16
1624,no,,test_sum_mlu_int32
1625,no,,test_sum_mlu_int64
1626,no,,test_sum_mlu_int8
1627,no,,test_sum_mlu_uint8
1628,no,,test_sum_neg_dim_mlu_float16
1629,no,,test_sum_neg_dim_mlu_float32
1630,no,,test_sum_neg_dim_mlu_float64
1631,no,,test_sum_neg_dim_mlu_int16
1632,no,,test_sum_neg_dim_mlu_int32
1633,no,,test_sum_neg_dim_mlu_int64
1634,no,,test_sum_neg_dim_mlu_int8
1635,no,,test_sum_neg_dim_mlu_uint8
1636,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 10 element(s) (out of 100) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.6166439056396484e-05 (0.41054075956344604 vs. 0.41056692600250244), which occurred at index (0, 1).
",test_svd_square_col_maj_mlu_float32
1637,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 8 element(s) (out of 100) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.630771251010966e-05 (0.011749808032795905 vs. 0.011776115745306015), which occurred at index (9, 1).
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_svd_square_col_maj_mlu_float64
1638,no,,test_svd_square_mlu_float32
1639,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_svd_square_mlu_float64
1640,no,,test_svd_tall_all_col_maj_mlu_float32
1641,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_svd_tall_all_col_maj_mlu_float64
1642,no,,test_svd_tall_all_mlu_float32
1643,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_svd_tall_all_mlu_float64
1644,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 14 element(s) (out of 100) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.0763447284698486e-05 (0.02306707575917244 vs. 0.02303631231188774), which occurred at index (19, 3).
",test_svd_tall_some_col_maj_mlu_float32
1645,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_svd_tall_some_col_maj_mlu_float64
1646,no,,test_svd_tall_some_mlu_float32
1647,yes,"Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
Expected tensor for argument #1 'input' to have one of the following scalar types: Float, Half; but got MLUDoubleType instead (while checking arguments for abs)
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 561][abs][thread:140219569719040][process:16986]: OpMethods::abs Op running on CPU!
",test_svd_tall_some_mlu_float64
1648,no,,test_t_inplace_mlu_float16
1649,no,,test_t_inplace_mlu_float32
1650,no,,test_t_inplace_mlu_float64
1651,no,,test_t_inplace_mlu_int16
1652,no,,test_t_inplace_mlu_int32
1653,no,,test_t_inplace_mlu_int64
1654,no,,test_t_inplace_mlu_int8
1655,no,,test_t_inplace_mlu_uint8
1656,no,,test_t_mlu_float16
1657,no,,test_t_mlu_float32
1658,no,,test_t_mlu_float64
1659,no,,test_t_mlu_int16
1660,no,,test_t_mlu_int32
1661,no,,test_t_mlu_int64
1662,no,,test_t_mlu_int8
1663,no,,test_t_mlu_uint8
1664,yes,"<class 'RuntimeError'> : _th_take not supported on CPUType for Half
",test_take_mlu_float16
1665,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_float32
1666,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_float64
1667,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_int16
1668,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_int32
1669,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_int64
1670,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_int8
1671,yes,"<class 'RuntimeError'> : Could not run 'aten::take' with arguments from the 'MLU' backend. 'aten::take' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_take_mlu_uint8
1672,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_tan_complex_mlu_complex128
1673,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_tan_complex_mlu_complex64
1674,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_tan_inplace_complex_mlu_complex128
1675,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_tan_inplace_complex_mlu_complex64
1676,yes,"<class 'RuntimeError'> : tan_vml_cpu not implemented for 'Half'
",test_tan_inplace_mlu_float16
1677,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_tan_inplace_mlu_float32
1678,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_tan_inplace_mlu_float64
1679,yes,"<class 'RuntimeError'> : tan_vml_cpu not implemented for 'Half'
",test_tan_mlu_float16
1680,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_tan_mlu_float32
1681,yes,"<class 'RuntimeError'> : DispatchStub: unsupported device typemlu
",test_tan_mlu_float64
1682,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_tanh_inplace_mlu_complex128
1683,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_tanh_inplace_mlu_complex64
1684,no,,test_tanh_inplace_mlu_float16
1685,no,,test_tanh_inplace_mlu_float32
1686,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 123 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.83296418330764 (-0.9930031285514909 vs. -2.825967311859131), which occurred at index (1, 4, 4).
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/activation_internal.cpp][line: 23][cnnl_activation_internal][thread:140219569719040][process:16986]: 
input must be float/half
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1125][tanh_][thread:140219569719040][process:16986]: OpMethods::tanh_ Op running on CPU!
",test_tanh_inplace_mlu_float64
1687,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<double>; c10::string_view = c10::basic_string_view<char>]
",test_tanh_mlu_complex128
1688,yes,"<class 'RuntimeError'> : getCnnlDataType() not supported for c10::complex<float>; c10::string_view = c10::basic_string_view<char>]
",test_tanh_mlu_complex64
1689,no,,test_tanh_mlu_float16
1690,no,,test_tanh_mlu_float32
1691,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/internal/activation_internal.cpp][line: 23][cnnl_activation_internal][thread:140219569719040][process:16986]: 
input must be float/half
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1118][tanh][thread:140219569719040][process:16986]: OpMethods::tanh Op running on CPU!
",test_tanh_mlu_float64
1692,no,,test_tolist_mlu_float16
1693,no,,test_tolist_mlu_float32
1694,no,,test_tolist_mlu_float64
1695,no,,test_tolist_mlu_int16
1696,no,,test_tolist_mlu_int32
1697,no,,test_tolist_mlu_int64
1698,no,,test_tolist_mlu_int8
1699,no,,test_tolist_mlu_uint8
1700,no,,test_topk_dim_desc_sort_mlu_float16
1701,no,,test_topk_dim_desc_sort_mlu_float32
1702,no,,test_topk_dim_desc_sort_mlu_float64
1703,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_desc_sort_mlu_int16
1704,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Int
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_desc_sort_mlu_int32
1705,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Long
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_desc_sort_mlu_int64
1706,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_desc_sort_mlu_int8
1707,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Byte
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_desc_sort_mlu_uint8
1708,no,,test_topk_dim_sort_mlu_float16
1709,no,,test_topk_dim_sort_mlu_float32
1710,no,,test_topk_dim_sort_mlu_float64
1711,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_sort_mlu_int16
1712,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Int
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_sort_mlu_int32
1713,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Long
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_sort_mlu_int64
1714,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_sort_mlu_int8
1715,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Byte
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_dim_sort_mlu_uint8
1716,no,,test_topk_neg_dim_sort_mlu_float16
1717,no,,test_topk_neg_dim_sort_mlu_float32
1718,no,,test_topk_neg_dim_sort_mlu_float64
1719,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Short
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_neg_dim_sort_mlu_int16
1720,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Int
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_neg_dim_sort_mlu_int32
1721,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Long
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_neg_dim_sort_mlu_int64
1722,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Char
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_neg_dim_sort_mlu_int8
1723,yes,"[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/cnnl/topk.cpp][line: 35][cnnl_topk_out][thread:140219569719040][process:16986]: 
cnnl_topk is not implemented for Byte
[WARNING][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/operators/op_methods.cpp][line: 1761][topk][thread:140219569719040][process:16986]: OpMethods::topk Op running on CPU!
",test_topk_neg_dim_sort_mlu_uint8
1724,yes,"<class 'RuntimeError'> : _th_trace not supported on CPUType for Half
",test_trace_mlu_float16
1725,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_float32
1726,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_float64
1727,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_int16
1728,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_int32
1729,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_int64
1730,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_int8
1731,yes,"<class 'RuntimeError'> : Could not run 'aten::trace' with arguments from the 'MLU' backend. 'aten::trace' is only available for these backends: [CPU, Autograd, Profiler, Tracer].
",test_trace_mlu_uint8
1732,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 24 element(s) (out of 24) whose difference(s) exceeded the margin of error (including 4 nan comparisons). The greatest difference was nan (0.2249755859375 vs. nan), which occurred at index (0, 0, 0, 0).
",test_transpose_inplace_mlu_float16
1733,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 24 element(s) (out of 24) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.2985816125721805e+17 (-1.1829363107681274 vs. -3.2985816125721805e+17), which occurred at index (0, 0, 0, 2).
",test_transpose_inplace_mlu_float32
1734,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 24 element(s) (out of 24) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.536622302763442 (-2.5366222151157074 vs. 8.76477343095419e-08), which occurred at index (0, 2, 0, 2).
",test_transpose_inplace_mlu_float64
1735,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 20 different element(s) (out of 24), with the greatest difference of 32635 (-1 vs. 32634) occuring at index (0, 1, 1, 2).
",test_transpose_inplace_mlu_int16
1736,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 23 different element(s) (out of 24), with the greatest difference of 594379635 (-5 vs. -594379640) occuring at index (0, 0, 0, 0).
",test_transpose_inplace_mlu_int32
1737,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 22 different element(s) (out of 24), with the greatest difference of 104224320 (0 vs. 104224320) occuring at index (0, 0, 0, 0).
",test_transpose_inplace_mlu_int64
1738,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 22 different element(s) (out of 24), with the greatest difference of 125 (2 vs. 127) occuring at index (0, 1, 0, 1).
",test_transpose_inplace_mlu_int8
1739,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 22 different element(s) (out of 24), with the greatest difference of 185 (2 vs. 187) occuring at index (0, 1, 1, 1).
",test_transpose_inplace_mlu_uint8
1740,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 24 element(s) (out of 24) whose difference(s) exceeded the margin of error (including 2 nan comparisons). The greatest difference was nan (1.8515625 vs. nan), which occurred at index (0, 0, 0, 0).
",test_transpose_inplace_neg_dim_mlu_float16
1741,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 24 element(s) (out of 24) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.2985816125721805e+17 (-1.5875365734100342 vs. -3.2985816125721805e+17), which occurred at index (0, 0, 0, 0).
",test_transpose_inplace_neg_dim_mlu_float32
1742,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 24 element(s) (out of 24) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 11.498749889320639 (0.9987480206073408 vs. -10.500001868713298), which occurred at index (0, 0, 1, 0).
",test_transpose_inplace_neg_dim_mlu_float64
1743,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 24 different element(s) (out of 24), with the greatest difference of 32630 (4 vs. 32634) occuring at index (0, 1, 2, 2).
",test_transpose_inplace_neg_dim_mlu_int16
1744,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 23 different element(s) (out of 24), with the greatest difference of 594379636 (-4 vs. -594379640) occuring at index (0, 0, 0, 0).
",test_transpose_inplace_neg_dim_mlu_int32
1745,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 19 different element(s) (out of 24), with the greatest difference of 104195442 (-2 vs. 104195440) occuring at index (0, 0, 1, 0).
",test_transpose_inplace_neg_dim_mlu_int64
1746,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 23 different element(s) (out of 24), with the greatest difference of 129 (-5 vs. 124) occuring at index (0, 0, 1, 0).
",test_transpose_inplace_neg_dim_mlu_int8
1747,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! Found 24 different element(s) (out of 24), with the greatest difference of 249 (5 vs. 254) occuring at index (0, 1, 0, 2).
",test_transpose_inplace_neg_dim_mlu_uint8
1748,no,,test_transpose_mlu_float16
1749,no,,test_transpose_mlu_float32
1750,no,,test_transpose_mlu_float64
1751,no,,test_transpose_mlu_int16
1752,no,,test_transpose_mlu_int32
1753,no,,test_transpose_mlu_int64
1754,no,,test_transpose_mlu_int8
1755,no,,test_transpose_mlu_uint8
1756,no,,test_transpose_neg_dim_mlu_float16
1757,no,,test_transpose_neg_dim_mlu_float32
1758,no,,test_transpose_neg_dim_mlu_float64
1759,no,,test_transpose_neg_dim_mlu_int16
1760,no,,test_transpose_neg_dim_mlu_int32
1761,no,,test_transpose_neg_dim_mlu_int64
1762,no,,test_transpose_neg_dim_mlu_int8
1763,no,,test_transpose_neg_dim_mlu_uint8
1764,no,,test_tril_inplace_mlu_float16
1765,no,,test_tril_inplace_mlu_float32
1766,no,,test_tril_inplace_mlu_float64
1767,no,,test_tril_inplace_mlu_int16
1768,no,,test_tril_inplace_mlu_int32
1769,no,,test_tril_inplace_mlu_int64
1770,no,,test_tril_inplace_mlu_int8
1771,no,,test_tril_inplace_mlu_uint8
1772,no,,test_tril_inplace_negative_mlu_float16
1773,no,,test_tril_inplace_negative_mlu_float32
1774,no,,test_tril_inplace_negative_mlu_float64
1775,no,,test_tril_inplace_negative_mlu_int16
1776,no,,test_tril_inplace_negative_mlu_int32
1777,no,,test_tril_inplace_negative_mlu_int64
1778,no,,test_tril_inplace_negative_mlu_int8
1779,no,,test_tril_inplace_negative_mlu_uint8
1780,no,,test_tril_inplace_positive_mlu_float16
1781,no,,test_tril_inplace_positive_mlu_float32
1782,no,,test_tril_inplace_positive_mlu_float64
1783,no,,test_tril_inplace_positive_mlu_int16
1784,no,,test_tril_inplace_positive_mlu_int32
1785,no,,test_tril_inplace_positive_mlu_int64
1786,no,,test_tril_inplace_positive_mlu_int8
1787,no,,test_tril_inplace_positive_mlu_uint8
1788,no,,test_tril_mlu_float16
1789,no,,test_tril_mlu_float32
1790,no,,test_tril_mlu_float64
1791,no,,test_tril_mlu_int16
1792,no,,test_tril_mlu_int32
1793,no,,test_tril_mlu_int64
1794,no,,test_tril_mlu_int8
1795,no,,test_tril_mlu_uint8
1796,no,,test_tril_negative_mlu_float16
1797,no,,test_tril_negative_mlu_float32
1798,no,,test_tril_negative_mlu_float64
1799,no,,test_tril_negative_mlu_int16
1800,no,,test_tril_negative_mlu_int32
1801,no,,test_tril_negative_mlu_int64
1802,no,,test_tril_negative_mlu_int8
1803,no,,test_tril_negative_mlu_uint8
1804,no,,test_tril_positive_mlu_float16
1805,no,,test_tril_positive_mlu_float32
1806,no,,test_tril_positive_mlu_float64
1807,no,,test_tril_positive_mlu_int16
1808,no,,test_tril_positive_mlu_int32
1809,no,,test_tril_positive_mlu_int64
1810,no,,test_tril_positive_mlu_int8
1811,no,,test_tril_positive_mlu_uint8
1812,no,,test_tril_zero_stride_mlu_float16
1813,no,,test_tril_zero_stride_mlu_float32
1814,no,,test_tril_zero_stride_mlu_float64
1815,no,,test_tril_zero_stride_mlu_int16
1816,no,,test_tril_zero_stride_mlu_int32
1817,no,,test_tril_zero_stride_mlu_int64
1818,no,,test_tril_zero_stride_mlu_int8
1819,no,,test_tril_zero_stride_mlu_uint8
1820,no,,test_triu_inplace_mlu_float16
1821,no,,test_triu_inplace_mlu_float32
1822,no,,test_triu_inplace_mlu_float64
1823,no,,test_triu_inplace_mlu_int16
1824,no,,test_triu_inplace_mlu_int32
1825,no,,test_triu_inplace_mlu_int64
1826,no,,test_triu_inplace_mlu_int8
1827,no,,test_triu_inplace_mlu_uint8
1828,no,,test_triu_inplace_negative_mlu_float16
1829,no,,test_triu_inplace_negative_mlu_float32
1830,no,,test_triu_inplace_negative_mlu_float64
1831,no,,test_triu_inplace_negative_mlu_int16
1832,no,,test_triu_inplace_negative_mlu_int32
1833,no,,test_triu_inplace_negative_mlu_int64
1834,no,,test_triu_inplace_negative_mlu_int8
1835,no,,test_triu_inplace_negative_mlu_uint8
1836,no,,test_triu_inplace_positive_mlu_float16
1837,no,,test_triu_inplace_positive_mlu_float32
1838,no,,test_triu_inplace_positive_mlu_float64
1839,no,,test_triu_inplace_positive_mlu_int16
1840,no,,test_triu_inplace_positive_mlu_int32
1841,no,,test_triu_inplace_positive_mlu_int64
1842,no,,test_triu_inplace_positive_mlu_int8
1843,no,,test_triu_inplace_positive_mlu_uint8
1844,no,,test_triu_mlu_float16
1845,no,,test_triu_mlu_float32
1846,no,,test_triu_mlu_float64
1847,no,,test_triu_mlu_int16
1848,no,,test_triu_mlu_int32
1849,no,,test_triu_mlu_int64
1850,no,,test_triu_mlu_int8
1851,no,,test_triu_mlu_uint8
1852,no,,test_triu_negative_mlu_float16
1853,no,,test_triu_negative_mlu_float32
1854,no,,test_triu_negative_mlu_float64
1855,no,,test_triu_negative_mlu_int16
1856,no,,test_triu_negative_mlu_int32
1857,no,,test_triu_negative_mlu_int64
1858,no,,test_triu_negative_mlu_int8
1859,no,,test_triu_negative_mlu_uint8
1860,no,,test_triu_positive_mlu_float16
1861,no,,test_triu_positive_mlu_float32
1862,no,,test_triu_positive_mlu_float64
1863,no,,test_triu_positive_mlu_int16
1864,no,,test_triu_positive_mlu_int32
1865,no,,test_triu_positive_mlu_int64
1866,no,,test_triu_positive_mlu_int8
1867,no,,test_triu_positive_mlu_uint8
1868,no,,test_triu_zero_stride_mlu_float16
1869,no,,test_triu_zero_stride_mlu_float32
1870,no,,test_triu_zero_stride_mlu_float64
1871,no,,test_triu_zero_stride_mlu_int16
1872,no,,test_triu_zero_stride_mlu_int32
1873,no,,test_triu_zero_stride_mlu_int64
1874,no,,test_triu_zero_stride_mlu_int8
1875,no,,test_triu_zero_stride_mlu_uint8
1876,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_inplace_tensor_with_inplace_mlu_float16
1877,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide_.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide_.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_inplace_tensor_with_inplace_mlu_float32
1878,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 7 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.3027672764565068e-05 (282.99305501986026 vs. 282.9930419921875), which occurred at index (2, 1, 4).
",test_true_divide_inplace_tensor_with_inplace_mlu_float64
1879,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_inplace_with_inplace_mlu_float16
1880,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_inplace_with_inplace_mlu_float32
1881,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_inplace_with_inplace_mlu_float64
1882,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_float16
1883,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_float32
1884,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_float64
1885,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_int16
1886,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_int32
1887,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_int64
1888,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_int8
1889,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_mlu_uint8
1890,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_float16
1891,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_float32
1892,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 8 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.1498467276614974e-05 (-530.591348130439 vs. -530.5913696289062), which occurred at index (2, 0, 0).
",test_true_divide_tensor_mlu_float64
1893,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_int16
1894,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_int32
1895,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_int64
1896,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_int8
1897,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_mlu_uint8
1898,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_with_inplace_mlu_float16
1899,yes,"<class 'RuntimeError'> : Could not run 'aten::true_divide.Tensor' with arguments from the 'MLU' backend. 'aten::true_divide.Tensor' is only available for these backends: [CPU, SparseCPU, Named, Autograd, Profiler, Tracer].
",test_true_divide_tensor_with_inplace_mlu_float32
1900,yes,"<class 'AssertionError'> : False is not true : Tensors failed to compare as equal! With rtol=0 and atol=1e-05, found 14 element(s) (out of 125) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.7790239528258098e-05 (-531.9268466378958 vs. -531.9268188476562), which occurred at index (2, 3, 2).
",test_true_divide_tensor_with_inplace_mlu_float64
1901,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_with_inplace_mlu_float16
1902,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_with_inplace_mlu_float32
1903,yes,"<class 'RuntimeError'> : dynamic_cast to MLUTensorImpl failed
[ERROR][/projs/framework/liuyuxin/env/pytorch/catch/torch_mlu/csrc/aten/core/tensor_util.cpp][line: 14][getMluTensorImpl][thread:140219569719040][process:16986]: 

The device type of tensor is not 'mlu'. 
Please check the python code where the 'result = mlu_model(input)' is called.
Please make sure the input.device is 'device(type='mlu', index=0)'.


",test_true_divide_with_inplace_mlu_float64
1904,yes,"<class 'RuntimeError'> : trunc_vml_cpu not implemented for 'Half'
",test_trunc_inplace_mlu_float16
1905,yes,"<class 'RuntimeError'> : Could not run 'aten::trunc.out' with arguments from the 'MLU' backend. 'aten::trunc.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_trunc_inplace_mlu_float32
1906,yes,"<class 'RuntimeError'> : Could not run 'aten::trunc.out' with arguments from the 'MLU' backend. 'aten::trunc.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_trunc_inplace_mlu_float64
1907,yes,"<class 'RuntimeError'> : trunc_vml_cpu not implemented for 'Half'
",test_trunc_mlu_float16
1908,yes,"<class 'RuntimeError'> : Could not run 'aten::trunc.out' with arguments from the 'MLU' backend. 'aten::trunc.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_trunc_mlu_float32
1909,yes,"<class 'RuntimeError'> : Could not run 'aten::trunc.out' with arguments from the 'MLU' backend. 'aten::trunc.out' is only available for these backends: [CPU, Named, Autograd, Profiler, Tracer].
",test_trunc_mlu_float64
1910,no,,test_unsqueeze_inplace_mlu_float16
1911,no,,test_unsqueeze_inplace_mlu_float32
1912,no,,test_unsqueeze_inplace_mlu_float64
1913,no,,test_unsqueeze_inplace_mlu_int16
1914,no,,test_unsqueeze_inplace_mlu_int32
1915,no,,test_unsqueeze_inplace_mlu_int64
1916,no,,test_unsqueeze_inplace_mlu_int8
1917,no,,test_unsqueeze_inplace_mlu_uint8
1918,no,,test_unsqueeze_inplace_neg_dim_mlu_float16
1919,no,,test_unsqueeze_inplace_neg_dim_mlu_float32
1920,no,,test_unsqueeze_inplace_neg_dim_mlu_float64
1921,no,,test_unsqueeze_inplace_neg_dim_mlu_int16
1922,no,,test_unsqueeze_inplace_neg_dim_mlu_int32
1923,no,,test_unsqueeze_inplace_neg_dim_mlu_int64
1924,no,,test_unsqueeze_inplace_neg_dim_mlu_int8
1925,no,,test_unsqueeze_inplace_neg_dim_mlu_uint8
1926,no,,test_unsqueeze_mlu_float16
1927,no,,test_unsqueeze_mlu_float32
1928,no,,test_unsqueeze_mlu_float64
1929,no,,test_unsqueeze_mlu_int16
1930,no,,test_unsqueeze_mlu_int32
1931,no,,test_unsqueeze_mlu_int64
1932,no,,test_unsqueeze_mlu_int8
1933,no,,test_unsqueeze_mlu_uint8
1934,no,,test_unsqueeze_neg_dim_mlu_float16
1935,no,,test_unsqueeze_neg_dim_mlu_float32
1936,no,,test_unsqueeze_neg_dim_mlu_float64
1937,no,,test_unsqueeze_neg_dim_mlu_int16
1938,no,,test_unsqueeze_neg_dim_mlu_int32
1939,no,,test_unsqueeze_neg_dim_mlu_int64
1940,no,,test_unsqueeze_neg_dim_mlu_int8
1941,no,,test_unsqueeze_neg_dim_mlu_uint8
1942,yes,"<class 'RuntimeError'> : std and var only supports CPU AND CUDA device type, got: mlu
",test_var_dim_mlu_float16
1943,yes,"<class 'RuntimeError'> : std and var only supports CPU AND CUDA device type, got: mlu
",test_var_dim_mlu_float32
1944,yes,"<class 'RuntimeError'> : std and var only supports CPU AND CUDA device type, got: mlu
",test_var_dim_mlu_float64
1945,yes,"<class 'RuntimeError'> : var only supports CPU AND CUDA device type, got: mlu
",test_var_mlu_float16
1946,yes,"<class 'RuntimeError'> : var only supports CPU AND CUDA device type, got: mlu
",test_var_mlu_float32
1947,yes,"<class 'RuntimeError'> : var only supports CPU AND CUDA device type, got: mlu
",test_var_mlu_float64
1948,yes,"<class 'RuntimeError'> : std and var only supports CPU AND CUDA device type, got: mlu
",test_var_neg_dim_mlu_float16
1949,yes,"<class 'RuntimeError'> : std and var only supports CPU AND CUDA device type, got: mlu
",test_var_neg_dim_mlu_float32
1950,yes,"<class 'RuntimeError'> : std and var only supports CPU AND CUDA device type, got: mlu
",test_var_neg_dim_mlu_float64
1951,no,,test_view_as_mlu_float16
1952,no,,test_view_as_mlu_float32
1953,no,,test_view_as_mlu_float64
1954,no,,test_view_as_mlu_int16
1955,no,,test_view_as_mlu_int32
1956,no,,test_view_as_mlu_int64
1957,no,,test_view_as_mlu_int8
1958,no,,test_view_as_mlu_uint8
1959,no,,test_view_contiguous_mlu_float16
1960,no,,test_view_contiguous_mlu_float32
1961,no,,test_view_contiguous_mlu_float64
1962,no,,test_view_contiguous_mlu_int16
1963,no,,test_view_contiguous_mlu_int32
1964,no,,test_view_contiguous_mlu_int64
1965,no,,test_view_contiguous_mlu_int8
1966,no,,test_view_contiguous_mlu_uint8
1967,no,,test_zero__mlu_float16
1968,no,,test_zero__mlu_float32
1969,no,,test_zero__mlu_float64
1970,no,,test_zero__mlu_int16
1971,no,,test_zero__mlu_int32
1972,no,,test_zero__mlu_int64
1973,no,,test_zero__mlu_int8
1974,no,,test_zero__mlu_uint8
